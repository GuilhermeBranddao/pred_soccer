{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Bibliotecas para treinamento\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from modelagem.train import model_trainer\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "# pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: E se criar um modelo para cada time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 21:18:43,929 | main | INFO | model_trainer | split_data | Dividindo os dados com valid_year=2024 e test_size=0.3...\n",
      "2025-04-03 21:18:43,933 | main | INFO | model_trainer | split_data | Tamanho dos conjuntos: Treino=3191, Teste=1368, Validação=380\n"
     ]
    }
   ],
   "source": [
    "# Definindo diretórios base\n",
    "BASE_DIR = os.path.dirname(Path(\"__file__\").resolve().parent)\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"pred_soccer\", \"modelagem\", 'feature_eng', 'data')\n",
    "MODEL_DIR = os.path.join(os.path.dirname(BASE_DIR), 'database')\n",
    "LOG_DIR = os.path.join(os.path.dirname(BASE_DIR), 'logs')\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, 'ft_df.csv'))\n",
    "df_train = model_trainer.main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dropping columns one wouldn't have before an actual match\n",
    "cols_to_drop = ['ls_winner', \n",
    "                ]\n",
    "\n",
    "df.drop(columns=cols_to_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora esse pré-processamento é feito em feature-eng!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando dados de treino e teste\n",
    "\n",
    "Nessa etapa estamos realizando o balanceamento de dados pois o modelo está com o vies com o desbalanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo manualmente os dados respeitando a ordem temporal\n",
    "split_index = int(len(df) * 0.8)  # Usando 80% dos dados para treino e 20% para teste\n",
    "\n",
    "#X_train, X_test = X[:split_index], X[split_index:]\n",
    "#y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "df_train = df[df['season']<2019] #['season'].value_counts()\n",
    "df_test = df[(df['season']>=2019) & (df['season']<2024)]\n",
    "df_valid = df[df['season']>=2024]\n",
    "\n",
    "X_train, y_train = df_train.drop(columns=['winner', 'season']), df_train['winner']\n",
    "X_test, y_test = df_test.drop(columns=['winner', 'season']), df_test['winner']\n",
    "X_valid, y_valid = df_valid.drop(columns=['winner', 'season']), df_valid['winner']\n",
    "\n",
    "# X_train, y_train = balancear_dados(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season\n",
       "2024    380\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winner\n",
       "2    0.502068\n",
       "0    0.264385\n",
       "1    0.233546\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como é o balanceamento da classe y\n",
    "\n",
    "df_train['winner'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winner\n",
       "2    0.502068\n",
       "0    0.264385\n",
       "1    0.233546\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como é ficou balanceamento da classe y\n",
    " \n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acredito que romover season não é mais necessario\n",
    "\n",
    "# df.drop(columns=['season'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listagem de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandomModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x_train, y_true):\n",
    "        self.y_true = y_true\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = [np.random.choice(self.y_true) for i in range(len(X))]\n",
    "        return  np.array(pred)\n",
    "    \n",
    "model = RandomModel()\n",
    "model.fit([1, 2, 3], [1, 2, 3])\n",
    "predictions = model.predict([1, 2, 3])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "\n",
    "# Creating models variable to iterate through each model and print result\n",
    "list_model = [\n",
    "    {'algorithm':'Logistic Regression', 'model':LogisticRegression(max_iter=3000)},\n",
    "    {'algorithm':'Logistic Regression tune', 'model':LogisticRegression(C=100, max_iter=3000, solver='newton-cg')},\n",
    "    {'algorithm':'Random Forest', 'model':RandomForestClassifier(class_weight='balanced')},\n",
    "    {'algorithm':'Gradient Boost', 'model':GradientBoostingClassifier()},\n",
    "    {'algorithm':'KNN', 'model':KNeighborsClassifier()},\n",
    "    {'algorithm':'Naive Bayes', 'model':GaussianNB()},\n",
    "    #{'algorithm':'SVM', 'model':SVC()},\n",
    "    {'algorithm':'Decision Tree (C5)', 'model':DecisionTreeClassifier(\n",
    "                                                max_depth=48, \n",
    "                                                min_samples_split=19, \n",
    "                                                min_samples_leaf=6, \n",
    "                                                max_features='log2', \n",
    "                                                criterion='gini')},\n",
    "                                        \n",
    "    {'algorithm':'Neural Network (MLP)', 'model':MLPClassifier(max_iter=3000)},\n",
    "    {'algorithm':'XGBoost', 'model':XGBClassifier()},\n",
    "    {'algorithm':'XGBoost tune', 'model':XGBClassifier(\n",
    "                                                max_depth=3, \n",
    "                                                learning_rate=0.1, \n",
    "                                                n_estimators=100, \n",
    "                                                objective='binary:logistic', \n",
    "                                                booster='gbtree', \n",
    "                                                gamma=0.1, \n",
    "                                                min_child_weight=1, \n",
    "                                                subsample=0.8, \n",
    "                                                colsample_bytree=0.8, \n",
    "                                                random_state=42)},\n",
    "    {'algorithm':'Random', 'model':RandomModel()},\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    ]\n",
    "        #'XGBoost': XGBClassifier(),\n",
    "        #'Multiple Linear Regression': LinearRegression(),\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções úteis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating loop to test which set of features is the best one for Logistic Regression\n",
    "def get_best_num_feature():\n",
    "    \"\"\"\n",
    "    Objetivo: Identificar o desempenho testando com varios numeros de features\n",
    "    \"\"\"\n",
    "    acc_results = []\n",
    "    n_features = []\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # best classifier on training data\n",
    "    clf = list_model[0]['model']\n",
    "\n",
    "    #X = df.drop(columns='winner')\n",
    "    #y = df['winner']\n",
    "\n",
    "    for i in range(12, len(X_train.columns)):\n",
    "        rfe = RFE(estimator=clf, n_features_to_select=i, step=1)\n",
    "        rfe.fit(X_train, y_train)\n",
    "        X_temp = rfe.transform(X)\n",
    "\n",
    "        np.random.seed(101)\n",
    "\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X_temp,y, test_size = 0.2)\n",
    "\n",
    "        X_train_trans = scaler.fit_transform(X_train)\n",
    "        X_test_trans = scaler.fit_transform(X_test)\n",
    "\n",
    "        start = time.time()\n",
    "        scores = cross_val_score(clf, X_train_trans, y_train ,scoring= 'accuracy', cv=5)\n",
    "        print(f\"Clf result : {scores.mean()}, +- {scores.std()} N_features: {i}\")\n",
    "        acc_results.append(scores.mean())\n",
    "        n_features.append(i)\n",
    "\n",
    "    plt.plot(n_features, acc_results)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('N features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_transform(X:pd.DataFrame, get_y_true=False):\n",
    "    \"\"\"\n",
    "    Recebe dataframe e retorna o dado pronto para ser realizado a predição\n",
    "    \"\"\"\n",
    "\n",
    "    #columns_pred = rfe.feature_names_in_\n",
    "\n",
    "    #X_valid = df_valid.drop(columns=['winner', 'season'])\n",
    "\n",
    "    #X_valid_trans = rfe.transform(df_valid[columns_pred])\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    X_valid_trans_scaler = scaler.fit_transform(X)\n",
    "\n",
    "    if get_y_true:\n",
    "        y_valid = X['winner']\n",
    "        return X_valid_trans_scaler, y_valid\n",
    "\n",
    "    return pd.DataFrame(X_valid_trans_scaler, columns=X.columns) \n",
    "\n",
    "\n",
    "def pred_data_valid(df_valid, rfe):\n",
    "    X_valid_trans_scaler = get_data_transform(df_valid, rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções de metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reultados: (Algo aqui)\n",
      "    Home_team: ------ 100.0%\n",
      "    Draw: ----------- 100.0%\n",
      "    Away_team: ------ 0.0%\n",
      "    ----------------------------\n"
     ]
    }
   ],
   "source": [
    "def calc_f1(precision, recal):\n",
    "    if precision + recal == 0:\n",
    "        return 0\n",
    "    return round(2 * ((precision * recal) / (precision + recal)), 2)\n",
    "\n",
    "def calc_recal(tp_count, fn_count):\n",
    "    if tp_count+fn_count == 0:\n",
    "        return 0\n",
    "    return round(tp_count / (tp_count+fn_count), 2)\n",
    "\n",
    "def calc_precision(tp_count, fp_count):\n",
    "    if tp_count+fp_count == 0:\n",
    "        return 0\n",
    "    return round(tp_count / (tp_count+fp_count), 2)\n",
    "\n",
    "def metrics_per_class(df_preds, classe):\n",
    "    \"\"\"\n",
    "        Realiza do calculos e de diversas metricas\n",
    "    \"\"\"\n",
    "    # Filtrar as predições e os rótulos verdadeiros para a classe atual\n",
    "    # True Positives (TP): Previsão correta de que a instância pertence à classe (ou seja, y_pred == classe e y_true == classe).\n",
    "    true_positives = df_preds[(df_preds['y_pred'] == classe) & (df_preds['y_true'] == classe)]\n",
    "\n",
    "    # True Negatives (TN): Previsão correta de que a instância não pertence à classe (ou seja, y_pred != classe e y_true != classe).\n",
    "    true_negatives = df_preds[(df_preds['y_pred'] != classe) & (df_preds['y_true'] != classe)]\n",
    "\n",
    "    # False Positives (FP): Previsão errada de que a instância pertence à classe, quando na verdade não pertence (ou seja, y_pred == classe e y_true != classe).\n",
    "    false_positives = df_preds[(df_preds['y_pred'] != classe) & (df_preds['y_true'] == classe)]\n",
    "\n",
    "    # False Negatives (FN): Previsão errada de que a instância não pertence à classe, quando na verdade pertence (ou seja, y_pred != classe e y_true == classe).\n",
    "    false_negatives = df_preds[(df_preds['y_pred'] == classe) & (df_preds['y_true'] != classe)]\n",
    "\n",
    "    # Contagem de cada um\n",
    "    tp_count = len(true_positives)\n",
    "    tn_count = len(true_negatives)\n",
    "    fp_count = len(false_positives)\n",
    "    fn_count = len(false_negatives)\n",
    "    \n",
    "    precision = calc_precision(tp_count, fp_count)\n",
    "    recal = calc_recal(tp_count, fn_count)\n",
    "    F1 = calc_f1(precision, recal)\n",
    "\n",
    "    return {\"precision\":precision, \"recal\":recal, \"F1\":F1}\n",
    "\n",
    "# def get_metrics_multiclass(y_pred:list, y_true:list):\n",
    "#     \"\"\" \n",
    "\n",
    "#     Realiza o calculo de varias metricas para cada classe\n",
    "\n",
    "#     Calcular a precisão: TP / (TP + FP)\n",
    "\n",
    "#     RETURN: {np.int64(0): 0.33, np.int64(2): 0.57, np.int64(1): 0.3}\n",
    "#     \"\"\"\n",
    "#     df_preds = pd.DataFrame(columns=['y_pred', 'y_true'])\n",
    "#     df_preds['y_pred'] = y_pred\n",
    "#     df_preds['y_true'] = y_true\n",
    "\n",
    "#     dict_precision = {}\n",
    "\n",
    "#     for classe in df_preds['y_true'].unique():\n",
    "#         dict_metrics_per_class = metrics_per_class(df_preds, classe)\n",
    "\n",
    "#         #precision, recal, F1\n",
    "#         dict_precision[classe] = dict_metrics_per_class\n",
    "\n",
    "#     return dict_precision\n",
    "\n",
    "# def get_precision_multiclass(metrics_multiclass):\n",
    "#     return {metrics:metrics_multiclass[metrics]['precision'] for metrics in metrics_multiclass}\n",
    "\n",
    "# def show_print_precision_multiclass(precision_multiclass, algorithm_name=''):\n",
    "#     \"\"\"\n",
    "#         Exibe de uma baneira mais visual as metricas de precisão\n",
    "#     \"\"\"\n",
    "#     home_team_precision = precision_multiclass.get(2, 0)\n",
    "#     draw_precision = precision_multiclass.get(0, 0)\n",
    "#     away_team_precision = precision_multiclass.get(1, 0)\n",
    "\n",
    "#     print(f'''Reultados: ({algorithm_name})\n",
    "#     Home_team: ------ {round(home_team_precision*100, 2)}%\n",
    "#     Draw: ----------- {round(draw_precision*100, 2)}%\n",
    "#     Away_team: ------ {round(away_team_precision*100, 2)}%\n",
    "#     ----------------------------''')\n",
    "\n",
    "# def get_precision(y_pred:list, y_true:list):\n",
    "#     \"\"\"\n",
    "#     Objetivo: Obtem a precisão\n",
    "\n",
    "#     Calcular a precisão: TP / (TP + FP)\n",
    "#     \"\"\"\n",
    "#     all_predicted = len(y_true)\n",
    "#     true_positives = sum(y_pred == y_true)\n",
    "#     precision = true_positives / all_predicted\n",
    "\n",
    "#     return precision\n",
    "\n",
    "y_pred = np.array([2, 1, 9, 4, 5, 6, 7, 8, 9, 10])\n",
    "y_true = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "get_precision(y_pred=y_pred,\n",
    "              y_true=y_true\n",
    "                )\n",
    "\n",
    "y_pred = np.array([1, 1, 1, 1, 0,\n",
    "                   0, 2, 2, 2, 2,\n",
    "                   0, 1])\n",
    "\n",
    "y_pred = np.array([0, 0, 0, 0, 0,\n",
    "                   0, 2, 2, 2, 2,\n",
    "                   0, 0])\n",
    "\n",
    "y_true = np.array([1, 1, 1, 1, 1,\n",
    "                   0, 2, 2, 2, 2,\n",
    "                   0, 1])\n",
    "\n",
    "\n",
    "# Existe apenas um 3 e eu acertei, mas a classe 3 saiu prejudicada\n",
    "# Quem deve sair prejudicado nesse exemplo é a classe 1\n",
    "metrics_multiclass = get_metrics_multiclass(y_pred=y_pred, \n",
    "                        y_true=y_true)\n",
    "\n",
    "precision_multiclass = get_precision_multiclass(metrics_multiclass)\n",
    "show_print_precision_multiclass(precision_multiclass=precision_multiclass, algorithm_name='Algo aqui')\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelagem.utils.metrics import get_metrics_multiclass, show_print_precision_multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Obter as features onde tenho mais desempenho em minhas features\n",
    "sampled_columns = X_train.columns.to_series().sample(n=30, random_state=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Passo para escolher o modelo que tem o melhor desempenho\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm: Logistic Regression | Media e Desvio: 0.52% +- 0.01% | Elapsed time: 0.14s\n",
      "algorithm: Logistic Regression tune | Media e Desvio: 0.51% +- 0.02% | Elapsed time: 0.14s\n",
      "algorithm: Random Forest | Media e Desvio: 0.5% +- 0.02% | Elapsed time: 3.01s\n",
      "algorithm: Gradient Boost | Media e Desvio: 0.5% +- 0.02% | Elapsed time: 13.2s\n",
      "algorithm: KNN | Media e Desvio: 0.43% +- 0.02% | Elapsed time: 0.18s\n",
      "algorithm: Naive Bayes | Media e Desvio: 0.45% +- 0.02% | Elapsed time: 0.03s\n",
      "algorithm: Decision Tree (C5) | Media e Desvio: 0.41% +- 0.02% | Elapsed time: 0.05s\n",
      "algorithm: Neural Network (MLP) | Media e Desvio: 0.47% +- 0.03% | Elapsed time: 13.2s\n",
      "algorithm: XGBoost | Media e Desvio: 0.49% +- 0.02% | Elapsed time: 1.97s\n",
      "algorithm: XGBoost tune | Media e Desvio: 0.51% +- 0.02% | Elapsed time: 0.97s\n",
      "algorithm: random | Media e Desvio: 0.38% +- 0.01% | Elapsed time: 0.07s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import TimeSeriesSplit # Essa técnica garante que os dados de treinamento estejam sempre antes dos dados de teste. O TimeSeriesSplit é uma forma de validação cruzada que preserva a ordem temporal dos dados.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "def run_cross_val_score(list_model, X, y, is_x_transform=False):\n",
    "    \"\"\"\n",
    "    O objetivo aqui é encontrar os melhores modelos\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for dict_model in list_model:\n",
    "        # X, y = balancear_dados(X=X, y=y, mode='subamostragem')\n",
    "\n",
    "        if is_x_transform:\n",
    "            X = get_data_transform(X, get_y_true=False)\n",
    "            \n",
    "\n",
    "        # Inicializar o modelo\n",
    "        clf = dict_model['model']\n",
    "\n",
    "        # Número de splits para o TimeSeriesSplit\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        fold_predictions = []\n",
    "        fold_true_values = []\n",
    "\n",
    "        list_accuracy = []\n",
    "        start = time.time()\n",
    "        for idx, (train_index, test_index) in enumerate(tscv.split(X), start=0):\n",
    "            X_kf_train, X_kf_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_kf_train, y_kf_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            clf.fit(X_kf_train, y_kf_train)\n",
    "            y_kf_pred = clf.predict(X_kf_test)\n",
    "            \n",
    "            fold_predictions.append(y_kf_pred)\n",
    "            fold_true_values.append(y_kf_test.values)\n",
    "            \n",
    "            # Você também pode calcular e armazenar a acurácia para cada fold\n",
    "            accuracy = accuracy_score(y_kf_test, y_kf_pred)\n",
    "            list_accuracy.append(accuracy)\n",
    "            #print(f'idx: {idx}, Fold accuracy: {accuracy}')\n",
    "\n",
    "        mean_score = round(np.array(list_accuracy).mean(), 2)\n",
    "        std_score = round(np.array(list_accuracy).std(), 2)\n",
    "        algorithm = dict_model['algorithm']\n",
    "        elapsed_time = round(time.time() - start, 2)\n",
    "\n",
    "        \n",
    "        print(f'algorithm: {algorithm} | Media e Desvio: {mean_score}% +- {std_score}% | Elapsed time: {round(elapsed_time, 2)}s')\n",
    "        \n",
    "        results.append({'algorithm': algorithm, \n",
    "                        'mean_accuracy': mean_score, \n",
    "                        'std_accuracy': std_score, \n",
    "                        'elapsed_time': elapsed_time,\n",
    "                        \n",
    "                        'fold_predictions': fold_predictions[0],\n",
    "                        'fold_true_values': fold_true_values[0],\n",
    "                        'list_accuracy': list_accuracy,\n",
    "                        \n",
    "                        })\n",
    "        #break\n",
    "        \n",
    "        #except Exception as e:\n",
    "        #    print(f'Error with {algorithm}: {e}')\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Exemplo de uso\n",
    "\n",
    "clf = list_model[0]['model']\n",
    "\n",
    "#columns_selected_0 = [\"at_loss_streak\",    \n",
    "#                    \"at_l_wavg_goals\",   \n",
    "#                    \"ht_l_points\",       \n",
    "#                    \"at_l_wavg_points\",  \n",
    "#                    \"ht_points\",         \n",
    "#                    \"at_l_goals_sf\",     \n",
    "#                    \"at_wins\",           \n",
    "#                    \"ht_l_wavg_goals\",   \n",
    "#                    \"ht_rank\",           \n",
    "#                    \"at_rank\",           \n",
    "#                    \"ht_days_ls_match\",  \n",
    "#                    \"ht_losses\",]\n",
    "\n",
    "\n",
    "\n",
    "X=df[X_train.columns]\n",
    "#X=df[columns_selected_0]\n",
    "y=df['winner']\n",
    "\n",
    "\n",
    "\n",
    "list_results = run_cross_val_score(list_model=list_model, \n",
    "                              X=X, \n",
    "                              y=y,\n",
    "                              is_x_transform=True)\n",
    "\n",
    "# Dados de exemplo\n",
    "# \n",
    "# TODO: rodar o kfold e em seguida plotar os resultados\n",
    "# TODO: Adicionar informação que qual time está jogando pode ser útil\n",
    "# Realiza o balanceamento entre as classe y\n",
    "# subamostragem\n",
    "# superamostragem\n",
    "# combinado\n",
    "\n",
    "# FIXME: Estou optando por realizar o corde de dados pois há uma grende diferença entre o balanceamento das classes\n",
    "    # O que acaba afetando no momento da previsão, pois melhora significativamente, o que eu ACHO que pode ser um erro\n",
    "    # Além disso, a superamostragem não resulveu o problema do desempenho do balanceamento, os modelo continuam com o vies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm: Logistic Regression | Media e Desvio: 0.46% +- 0.01% | Elapsed time: 4.34s\n",
    "# algorithm: Logistic Regression tune | Media e Desvio: 0.46% +- 0.01% | Elapsed time: 0.67s\n",
    "# algorithm: Random Forest | Media e Desvio: 0.42% +- 0.02% | Elapsed time: 5.14s\n",
    "# algorithm: Gradient Boost | Media e Desvio: 0.44% +- 0.02% | Elapsed time: 22.72s\n",
    "# algorithm: KNN | Media e Desvio: 0.37% +- 0.01% | Elapsed time: 0.31s\n",
    "# algorithm: Naive Bayes | Media e Desvio: 0.41% +- 0.02% | Elapsed time: 0.05s\n",
    "# algorithm: Decision Tree (C5) | Media e Desvio: 0.37% +- 0.01% | Elapsed time: 0.08s\n",
    "# algorithm: Neural Network (MLP) | Media e Desvio: 0.41% +- 0.02% | Elapsed time: 11.94s\n",
    "# algorithm: XGBoost | Media e Desvio: 0.41% +- 0.02% | Elapsed time: 2.49s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_ metrics_multiclass.get(0, None)\n",
    "\n",
    "# for results in list_results:\n",
    "    # algorithm_name = results['algorithm']\n",
    "    # y_pred = results['fold_predictions']\n",
    "    # y_true = results['fold_true_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando uma lista para armazenar os dados antes de criar o DataFrame\n",
    "all_metrics = []\n",
    "\n",
    "for results in list_results:\n",
    "    metrics_multiclass = get_metrics_multiclass(\n",
    "        y_pred=results['fold_predictions'], \n",
    "        y_true=results['fold_true_values']\n",
    "    )\n",
    "    \n",
    "    # Iterando pelas classes (home_team, draw, away_team)\n",
    "    for class_label, class_metrics in metrics_multiclass.items():\n",
    "        class_metrics[\"results\"] = {2: \"home_team\", 0: \"draw\", 1: \"away_team\"}.get(class_label, \"unknown\")\n",
    "        class_metrics[\"algorithm\"] = results['algorithm']\n",
    "        all_metrics.append(class_metrics)\n",
    "\n",
    "# Criando o DataFrame a partir da lista de métricas\n",
    "df_all_metrics = pd.DataFrame(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recal</th>\n",
       "      <th>F1</th>\n",
       "      <th>results</th>\n",
       "      <th>algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.32</td>\n",
       "      <td>away_team</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.24</td>\n",
       "      <td>draw</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.69</td>\n",
       "      <td>home_team</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.29</td>\n",
       "      <td>away_team</td>\n",
       "      <td>Logistic Regression tune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.28</td>\n",
       "      <td>draw</td>\n",
       "      <td>Logistic Regression tune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>home_team</td>\n",
       "      <td>Logistic Regression tune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.34</td>\n",
       "      <td>away_team</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.21</td>\n",
       "      <td>draw</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.68</td>\n",
       "      <td>home_team</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.33</td>\n",
       "      <td>away_team</td>\n",
       "      <td>Gradient Boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.26</td>\n",
       "      <td>draw</td>\n",
       "      <td>Gradient Boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.65</td>\n",
       "      <td>home_team</td>\n",
       "      <td>Gradient Boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.29</td>\n",
       "      <td>away_team</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.28</td>\n",
       "      <td>draw</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>home_team</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.37</td>\n",
       "      <td>away_team</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.24</td>\n",
       "      <td>draw</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.54</td>\n",
       "      <td>home_team</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.23</td>\n",
       "      <td>away_team</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>draw</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>home_team</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.31</td>\n",
       "      <td>away_team</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.23</td>\n",
       "      <td>draw</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>home_team</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.35</td>\n",
       "      <td>away_team</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "      <td>draw</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>home_team</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.34</td>\n",
       "      <td>away_team</td>\n",
       "      <td>XGBoost tune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.23</td>\n",
       "      <td>draw</td>\n",
       "      <td>XGBoost tune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>home_team</td>\n",
       "      <td>XGBoost tune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>away_team</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.20</td>\n",
       "      <td>draw</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>home_team</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    precision  recal    F1    results                 algorithm\n",
       "0        0.27   0.39  0.32  away_team       Logistic Regression\n",
       "1        0.22   0.27  0.24       draw       Logistic Regression\n",
       "2        0.76   0.63  0.69  home_team       Logistic Regression\n",
       "3        0.24   0.37  0.29  away_team  Logistic Regression tune\n",
       "4        0.34   0.24  0.28       draw  Logistic Regression tune\n",
       "5        0.63   0.65  0.64  home_team  Logistic Regression tune\n",
       "6        0.28   0.44  0.34  away_team             Random Forest\n",
       "7        0.16   0.32  0.21       draw             Random Forest\n",
       "8        0.81   0.59  0.68  home_team             Random Forest\n",
       "9        0.29   0.37  0.33  away_team            Gradient Boost\n",
       "10       0.24   0.29  0.26       draw            Gradient Boost\n",
       "11       0.70   0.60  0.65  home_team            Gradient Boost\n",
       "12       0.28   0.31  0.29  away_team                       KNN\n",
       "13       0.35   0.23  0.28       draw                       KNN\n",
       "14       0.49   0.59  0.54  home_team                       KNN\n",
       "15       0.50   0.30  0.37  away_team               Naive Bayes\n",
       "16       0.22   0.26  0.24       draw               Naive Bayes\n",
       "17       0.48   0.62  0.54  home_team               Naive Bayes\n",
       "18       0.19   0.28  0.23  away_team        Decision Tree (C5)\n",
       "19       0.26   0.23  0.24       draw        Decision Tree (C5)\n",
       "20       0.59   0.55  0.57  home_team        Decision Tree (C5)\n",
       "21       0.29   0.34  0.31  away_team      Neural Network (MLP)\n",
       "22       0.26   0.20  0.23       draw      Neural Network (MLP)\n",
       "23       0.56   0.59  0.57  home_team      Neural Network (MLP)\n",
       "24       0.33   0.38  0.35  away_team                   XGBoost\n",
       "25       0.25   0.26  0.25       draw                   XGBoost\n",
       "26       0.63   0.59  0.61  home_team                   XGBoost\n",
       "27       0.31   0.37  0.34  away_team              XGBoost tune\n",
       "28       0.20   0.28  0.23       draw              XGBoost tune\n",
       "29       0.73   0.61  0.66  home_team              XGBoost tune\n",
       "30       0.23   0.21  0.22  away_team                    random\n",
       "31       0.21   0.19  0.20       draw                    random\n",
       "32       0.49   0.53  0.51  home_team                    random"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reultados: (Logistic Regression)\n",
      "    Home_team: ------ 76.0%\n",
      "    Draw: ----------- 22.0%\n",
      "    Away_team: ------ 27.0%\n",
      "    ----------------------------\n",
      "Reultados: (Logistic Regression tune)\n",
      "    Home_team: ------ 63.0%\n",
      "    Draw: ----------- 34.0%\n",
      "    Away_team: ------ 24.0%\n",
      "    ----------------------------\n",
      "Reultados: (Random Forest)\n",
      "    Home_team: ------ 81.0%\n",
      "    Draw: ----------- 16.0%\n",
      "    Away_team: ------ 28.0%\n",
      "    ----------------------------\n",
      "Reultados: (Gradient Boost)\n",
      "    Home_team: ------ 70.0%\n",
      "    Draw: ----------- 24.0%\n",
      "    Away_team: ------ 29.0%\n",
      "    ----------------------------\n",
      "Reultados: (KNN)\n",
      "    Home_team: ------ 49.0%\n",
      "    Draw: ----------- 35.0%\n",
      "    Away_team: ------ 28.0%\n",
      "    ----------------------------\n",
      "Reultados: (Naive Bayes)\n",
      "    Home_team: ------ 48.0%\n",
      "    Draw: ----------- 22.0%\n",
      "    Away_team: ------ 50.0%\n",
      "    ----------------------------\n",
      "Reultados: (Decision Tree (C5))\n",
      "    Home_team: ------ 59.0%\n",
      "    Draw: ----------- 26.0%\n",
      "    Away_team: ------ 19.0%\n",
      "    ----------------------------\n",
      "Reultados: (Neural Network (MLP))\n",
      "    Home_team: ------ 56.0%\n",
      "    Draw: ----------- 26.0%\n",
      "    Away_team: ------ 29.0%\n",
      "    ----------------------------\n",
      "Reultados: (XGBoost)\n",
      "    Home_team: ------ 63.0%\n",
      "    Draw: ----------- 25.0%\n",
      "    Away_team: ------ 33.0%\n",
      "    ----------------------------\n",
      "Reultados: (XGBoost tune)\n",
      "    Home_team: ------ 73.0%\n",
      "    Draw: ----------- 20.0%\n",
      "    Away_team: ------ 31.0%\n",
      "    ----------------------------\n",
      "Reultados: (random)\n",
      "    Home_team: ------ 49.0%\n",
      "    Draw: ----------- 21.0%\n",
      "    Away_team: ------ 23.0%\n",
      "    ----------------------------\n"
     ]
    }
   ],
   "source": [
    "for results in list_results:\n",
    "    metrics_multiclass = get_metrics_multiclass(y_pred=results['fold_predictions'], \n",
    "                           y_true=results['fold_true_values'])\n",
    "    \n",
    "    precision_multiclass = get_precision_multiclass(metrics_multiclass=metrics_multiclass)\n",
    "\n",
    "    print_precision_multiclass = show_print_precision_multiclass(precision_multiclass,algorithm_name=results['algorithm'])\n",
    "\n",
    "    #print(print_precision_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reultados: (Logistic Regression)\n",
    "#     Home_team: ------ 70.0%\n",
    "#     Draw: ----------- 7.0%\n",
    "#     Away_team: ------ 57.0%\n",
    "#     ----------------------------\n",
    "# Reultados: (Logistic Regression tune)\n",
    "#     Home_team: ------ 71.0%\n",
    "#     Draw: ----------- 10.0%\n",
    "#     Away_team: ------ 50.0%\n",
    "#     ----------------------------\n",
    "# Reultados: (Random Forest)\n",
    "#     Home_team: ------ 48.0%\n",
    "#     Draw: ----------- 20.0%\n",
    "#     Away_team: ------ 51.0%\n",
    "#     ----------------------------\n",
    "# Reultados: (Gradient Boost)\n",
    "#     Home_team: ------ 49.0%\n",
    "#     Draw: ----------- 24.0%\n",
    "#     Away_team: ------ 50.0%\n",
    "#     ----------------------------\n",
    "# Reultados: (KNN)\n",
    "#     Home_team: ------ 27.0%\n",
    "#     Draw: ----------- 42.0%\n",
    "#     Away_team: ------ 44.0%\n",
    "#     ----------------------------\n",
    "# Reultados: (Naive Bayes)\n",
    "#     Home_team: ------ 47.0%\n",
    "#     Draw: ----------- 19.0%\n",
    "#     Away_team: ------ 46.0%\n",
    "#     ----------------------------\n",
    "# Reultados: (Decision Tree (C5))\n",
    "#     Home_team: ------ 40.0%\n",
    "#     Draw: ----------- 33.0%\n",
    "#     Away_team: ------ 40.0%\n",
    "#     ----------------------------\n",
    "# Reultados: (Neural Network (MLP))\n",
    "#     Home_team: ------ 80.0%\n",
    "#     Draw: ----------- 4.0%\n",
    "#     Away_team: ------ 44.0%\n",
    "#     ----------------------------\n",
    "# Reultados: (XGBoost)\n",
    "#     Home_team: ------ 49.0%\n",
    "#     Draw: ----------- 25.0%\n",
    "#     Away_team: ------ 45.0%\n",
    "#     ----------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando resultados aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(2): {'precision': 0.36, 'recal': 0.34, 'F1': 0.35},\n",
       " np.int64(1): {'precision': 0.32, 'recal': 0.33, 'F1': 0.32},\n",
       " np.int64(0): {'precision': 0.31, 'recal': 0.31, 'F1': 0.31}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gerando resultados aleatorios\n",
    "\n",
    "random_predictions = [choice([0, 1, 2]) for i in range(1000)]\n",
    "random_true_values = [choice([0, 1, 2]) for i in range(1000)]\n",
    "\n",
    "get_metrics_multiclass(y_pred=random_predictions, y_true=random_true_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratando dados \n",
    "\n",
    "- Transformando e usando scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectec_columns_h = [\n",
    "                \"at_wins\",\n",
    "                \"at_l_wavg_points\",\n",
    "                \"ht_l_points\",\n",
    "                \"at_loss_streak\",\n",
    "                \"ht_points\",\n",
    "                \"at_l_goals_sf\",\n",
    "                \"at_l_wavg_goals\",\n",
    "                \"ht_losses\",\n",
    "                \"ht_days_ls_match\",\n",
    "                \"ht_l_wavg_goals\",\n",
    "                \"at_rank\",\n",
    "                \"ht_rank\",\n",
    "                \"at_draws\",\n",
    "                \"at_win_streak\",\n",
    "                \"at_ls_rank\"]\n",
    "\n",
    "\n",
    "X_train_copy = X_train.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "\n",
    "X_train_copy = X_train_copy#[selectec_columns_h]\n",
    "X_test_copy = X_test_copy#[selectec_columns_h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(len(X_train_copy.columns)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_trans_scaler = get_data_transform(X_train_copy, get_y_true=False)\n",
    "X_test_trans_scaler = get_data_transform(X_test_copy, get_y_true=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importâncias das features para class_0:\n",
      "                        coef\n",
      "at_wins             1.179542\n",
      "at_l_wavg_points    1.122434\n",
      "at_loss_streak      1.066066\n",
      "ht_l_points         1.055765\n",
      "at_l_goals_sf       1.055585\n",
      "ht_points           1.053262\n",
      "at_l_wavg_goals     1.047749\n",
      "ht_losses           1.028276\n",
      "ht_l_wavg_goals     1.023489\n",
      "at_rank             1.013795\n",
      "at_draws            1.011897\n",
      "ht_days_ls_match    1.011351\n",
      "ht_rank             1.006518\n",
      "rodada              1.002087\n",
      "at_ls_rank          1.000020\n",
      "ht_l_goals          0.999814\n",
      "ht_goals            0.999443\n",
      "ht_ls_rank          0.998671\n",
      "ht_goals_sf         0.998596\n",
      "at_goals_sf         0.998298\n",
      "at_l_goals          0.994356\n",
      "ht_l_goals_sf       0.991112\n",
      "at_days_ls_match    0.988986\n",
      "at_goals            0.983164\n",
      "at_win_streak       0.982328\n",
      "ht_loss_streak      0.976708\n",
      "ht_draws            0.968172\n",
      "at_losses           0.964970\n",
      "at_draw_streak      0.959451\n",
      "ht_win_streak       0.955041\n",
      "ht_l_wavg_points    0.952687\n",
      "at_points           0.950729\n",
      "at_l_wavg_goals_sf  0.941467\n",
      "ht_l_wavg_goals_sf  0.938049\n",
      "at_l_points         0.932280\n",
      "ht_draw_streak      0.906319\n",
      "ht_wins             0.884302\n",
      "\n",
      "\n",
      "Importâncias das features para class_1:\n",
      "                        coef\n",
      "ht_win_streak       1.124218\n",
      "ht_draw_streak      1.102629\n",
      "at_losses           1.073265\n",
      "ht_rank             1.065039\n",
      "at_l_wavg_goals_sf  1.057978\n",
      "ht_wins             1.045149\n",
      "ht_l_wavg_goals_sf  1.037320\n",
      "at_win_streak       1.036557\n",
      "ht_l_wavg_goals     1.032374\n",
      "at_draws            1.030306\n",
      "at_days_ls_match    1.026013\n",
      "ht_l_goals_sf       1.016157\n",
      "ht_goals_sf         1.010202\n",
      "ht_loss_streak      1.010113\n",
      "at_draw_streak      1.009961\n",
      "at_l_goals_sf       1.009086\n",
      "at_points           1.004693\n",
      "at_l_points         1.002604\n",
      "at_ls_rank          1.002594\n",
      "ht_ls_rank          1.001473\n",
      "at_goals            1.001255\n",
      "ht_points           1.000793\n",
      "at_l_goals          1.000418\n",
      "at_goals_sf         1.000200\n",
      "ht_l_points         0.996524\n",
      "ht_l_goals          0.995460\n",
      "rodada              0.991230\n",
      "at_l_wavg_goals     0.990258\n",
      "ht_goals            0.986441\n",
      "ht_days_ls_match    0.980279\n",
      "ht_draws            0.965791\n",
      "ht_losses           0.945170\n",
      "at_wins             0.944940\n",
      "at_l_wavg_points    0.927364\n",
      "at_rank             0.919137\n",
      "at_loss_streak      0.917993\n",
      "ht_l_wavg_points    0.891502\n",
      "\n",
      "\n",
      "Importâncias das features para class_2:\n",
      "                        coef\n",
      "ht_l_wavg_points    1.177409\n",
      "ht_wins             1.081984\n",
      "at_rank             1.073172\n",
      "at_l_points         1.069853\n",
      "ht_draws            1.069460\n",
      "at_points           1.046911\n",
      "at_draw_streak      1.031984\n",
      "ht_losses           1.028917\n",
      "ht_l_wavg_goals_sf  1.027689\n",
      "at_loss_streak      1.021825\n",
      "at_goals            1.015850\n",
      "ht_goals            1.014311\n",
      "ht_loss_streak      1.013597\n",
      "ht_days_ls_match    1.008668\n",
      "rodada              1.006747\n",
      "at_l_goals          1.005256\n",
      "ht_l_goals          1.004748\n",
      "at_l_wavg_goals_sf  1.003964\n",
      "at_goals_sf         1.001504\n",
      "ht_draw_streak      1.000667\n",
      "ht_ls_rank          0.999858\n",
      "at_ls_rank          0.997393\n",
      "ht_l_goals_sf       0.992925\n",
      "ht_goals_sf         0.991292\n",
      "at_days_ls_match    0.985502\n",
      "at_win_streak       0.982088\n",
      "at_losses           0.965559\n",
      "at_l_wavg_goals     0.963816\n",
      "at_l_wavg_points    0.960702\n",
      "at_draws            0.959174\n",
      "ht_l_points         0.950485\n",
      "ht_points           0.948679\n",
      "ht_l_wavg_goals     0.946411\n",
      "at_l_goals_sf       0.938812\n",
      "ht_rank             0.932853\n",
      "ht_win_streak       0.931381\n",
      "at_wins             0.897186\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# column importances for each class\n",
    "\n",
    "# Se eu quisar prever apenas EMPATES, tenho mais ganho \n",
    "\n",
    "# TODO: Seria útil analisar um gráfico de correlação para ver quais colunas influenciam \n",
    "from sklearn.feature_selection import RFE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Função para realizar RFE e retornar colunas importantes\n",
    "def perform_rfe(clf, X_train, y_train, num_columns):\n",
    "    \"\"\"\n",
    "    Realiza a Recursive Feature Elimination (RFE) para selecionar as features mais importantes.\n",
    "\n",
    "    Args:\n",
    "    clf: O classificador base utilizado para RFE.\n",
    "    X_train: Dados de treino.\n",
    "    y_train: Labels correspondentes ao treino.\n",
    "    num_columns: Número de colunas a serem selecionadas.\n",
    "\n",
    "    Returns:\n",
    "    featured_columns: Lista das colunas selecionadas como importantes.\n",
    "    rfe: Objeto RFE treinado.\n",
    "    \"\"\"\n",
    "    rfe = RFE(estimator=clf, n_features_to_select=num_columns, step=1)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    \n",
    "    # Pegando os nomes das colunas selecionadas\n",
    "    featured_columns = pd.DataFrame(rfe.support_,\n",
    "                                    index=X_train.columns,\n",
    "                                    columns=['is_in'])\n",
    "    \n",
    "    featured_columns = featured_columns[featured_columns.is_in == True].index.tolist()\n",
    "    \n",
    "    return featured_columns, rfe\n",
    "\n",
    "# Função para calcular a importância das features\n",
    "def calculate_feature_importances(rfe, featured_columns):\n",
    "    \"\"\"\n",
    "    Calcula as importâncias das features selecionadas usando os coeficientes do modelo.\n",
    "\n",
    "    Args:\n",
    "    rfe: Objeto RFE treinado.\n",
    "    featured_columns: Lista das colunas selecionadas.\n",
    "\n",
    "    Returns:\n",
    "    importances: Dicionário com as importâncias das features para cada classe.\n",
    "    \"\"\"\n",
    "    # Exponenciando os coeficientes para cada classe (multiclasse)\n",
    "    importances = {}\n",
    "    for idx, class_coef in enumerate(rfe.estimator_.coef_):\n",
    "        importance_df = pd.DataFrame(np.exp(class_coef),\n",
    "                                     index=featured_columns,\n",
    "                                     columns=['coef']).sort_values('coef', ascending=False)\n",
    "        importances[f'class_{idx}'] = importance_df\n",
    "    \n",
    "    return importances\n",
    "\n",
    "# Aplicando o RFE\n",
    "clf = list_model[0]['model']\n",
    "num_columns = len(X_train_copy.columns)\n",
    "\n",
    "# Obtenção das colunas selecionadas e RFE treinado\n",
    "featured_columns, rfe = perform_rfe(clf, X_train_copy, y_train, num_columns=num_columns)\n",
    "\n",
    "# Cálculo das importâncias das features para cada classe\n",
    "importances = calculate_feature_importances(rfe, featured_columns)\n",
    "\n",
    "# Exibindo as importâncias para cada classe\n",
    "for class_name, importance_df in importances.items():\n",
    "    print(f\"Importâncias das features para {class_name}:\")\n",
    "    print(importance_df)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempenho usando os dados de teste\n"
     ]
    }
   ],
   "source": [
    "print('Desempenho usando os dados de teste')\n",
    "\n",
    "# Modelos com Sem fine tune, só peguei e rodei\n",
    "\n",
    "def train_models(list_model, X_train_trans_scaler):\n",
    "    \n",
    "    for dict_model in list_model:\n",
    "        mdl = dict_model['model'].fit(X_train_trans_scaler, y_train)\n",
    "\n",
    "        y_pred = mdl.predict(X_test_trans_scaler)\n",
    "        acc = round(accuracy_score(y_pred=y_pred, y_true=y_test.values), 2)\n",
    "        \n",
    "        metrics_multiclass = get_metrics_multiclass(y_pred=y_pred, \n",
    "                        y_true=y_test.values)\n",
    "        dict_precision = get_precision_multiclass(metrics_multiclass=metrics_multiclass)\n",
    "        dict_model['home_precision_%'] = dict_precision.get(2, None)\n",
    "        dict_model['draw_precision_%'] = dict_precision.get(0, None)\n",
    "        dict_model['away_precision_%'] = dict_precision.get(1, None)\n",
    "        dict_model['mdl'] = mdl \n",
    "        dict_model['accuracy_%'] = acc\n",
    "        dict_model['pred'] = y_pred\n",
    "\n",
    "        #print(f'{dict_model[\"algorithm\"]}: {acc}%')\n",
    "\n",
    "    return pd.DataFrame(list_model)\n",
    "\n",
    "df_results = train_models(list_model, X_train_trans_scaler)\n",
    "\n",
    "#df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>home_precision_%</th>\n",
       "      <th>draw_precision_%</th>\n",
       "      <th>away_precision_%</th>\n",
       "      <th>accuracy_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>57.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>49.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>43.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aleatorio</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              algorithm  home_precision_%  draw_precision_%  away_precision_%  \\\n",
       "0   Logistic Regression              57.0              31.0              53.0   \n",
       "1           Naive Bayes              49.0              32.0              45.0   \n",
       "2  Neural Network (MLP)              43.0              32.0              56.0   \n",
       "3        Gradient Boost              44.0              28.0              52.0   \n",
       "4         Random Forest              37.0              34.0              52.0   \n",
       "5               XGBoost              31.0              34.0              56.0   \n",
       "6                   KNN              31.0              43.0              41.0   \n",
       "7    Decision Tree (C5)              27.0              36.0              47.0   \n",
       "8             Aleatorio              31.0              34.0              33.0   \n",
       "\n",
       "   accuracy_%  \n",
       "0        49.0  \n",
       "1        43.0  \n",
       "2        43.0  \n",
       "3        42.0  \n",
       "4        40.0  \n",
       "5        38.0  \n",
       "6        37.0  \n",
       "7        34.0  \n",
       "8        33.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figura 2 \n",
    "\n",
    "# Gerando resultados aleatorios\n",
    "\n",
    "num_lines = X_train_trans_scaler.shape[0]\n",
    "random_predictions = [choice([0, 1, 2]) for i in range(num_lines)]\n",
    "random_true_values = [choice([0, 1, 2]) for i in range(num_lines)]\n",
    "\n",
    "result_aleatorio = get_metrics_multiclass(y_pred=random_predictions, y_true=random_true_values)\n",
    "\n",
    "algorithm = 'Aleatorio'\n",
    "home_precision, home_recal, home_f1 = result_aleatorio[1].values()\n",
    "draw_precision, draw_recal, draw_f1 = result_aleatorio[0].values()\n",
    "away_precision, away_recal, away_f1 = result_aleatorio[2].values()\n",
    "\n",
    "accuracy = round(accuracy_score(y_pred=random_predictions,\n",
    "                           y_true=random_true_values), 2)\n",
    "\n",
    "df_result_aleatorio = pd.DataFrame([{\"algorithm\":algorithm,\n",
    "                \"home_precision_%\":home_precision,\n",
    "                \"draw_precision_%\":draw_precision,\n",
    "                \"away_precision_%\":away_precision,\n",
    "                \"accuracy_%\":accuracy}])\n",
    "\n",
    "\n",
    "# Removendo linhas indesejadas\n",
    "df_results.drop(index=1, inplace=True)\n",
    "\n",
    "# Melhorando porcentagens\n",
    "df_results = pd.concat([df_results, df_result_aleatorio]) \n",
    "df_results[['home_precision_%','draw_precision_%','away_precision_%','accuracy_%']] = df_results[['home_precision_%','draw_precision_%','away_precision_%','accuracy_%']] * 100\n",
    "df_results[['algorithm','home_precision_%','draw_precision_%','away_precision_%','accuracy_%']].sort_values(by='accuracy_%', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Logistic Regression tune</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Decision Tree (C5)</th>\n",
       "      <th>Neural Network (MLP)</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Logistic Regression  Logistic Regression tune  Random Forest  \\\n",
       "0                    1                         1              1   \n",
       "1                    0                         0              1   \n",
       "2                    2                         2              0   \n",
       "3                    0                         0              1   \n",
       "4                    2                         2              2   \n",
       "\n",
       "   Gradient Boost  KNN  Naive Bayes  Decision Tree (C5)  Neural Network (MLP)  \\\n",
       "0               1    1            1                   1                     1   \n",
       "1               1    0            0                   1                     0   \n",
       "2               2    0            0                   1                     1   \n",
       "3               1    1            0                   2                     1   \n",
       "4               0    1            2                   1                     2   \n",
       "\n",
       "   XGBoost  \n",
       "0        1  \n",
       "1        0  \n",
       "2        2  \n",
       "3        0  \n",
       "4        1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_preds(list_model):\n",
    "\n",
    "    dict_concat_preds = {}\n",
    "    for idx in range(len(list_model)):\n",
    "        \n",
    "        dict_concat_preds[list_model[idx]['algorithm']] = list_model[idx]['pred']\n",
    "\n",
    "    df_concat_preds = pd.DataFrame(dict_concat_preds)\n",
    "    return df_concat_preds\n",
    "\n",
    "df_concat_preds = concat_preds(list_model)\n",
    "df_concat_preds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Logistic Regression tune</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Decision Tree (C5)</th>\n",
       "      <th>Neural Network (MLP)</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>pred_mode</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Logistic Regression  Logistic Regression tune  Random Forest  \\\n",
       "0                    1                         1              1   \n",
       "1                    0                         0              1   \n",
       "2                    2                         2              0   \n",
       "3                    0                         0              1   \n",
       "4                    2                         2              2   \n",
       "\n",
       "   Gradient Boost  KNN  Naive Bayes  Decision Tree (C5)  Neural Network (MLP)  \\\n",
       "0               1    1            1                   1                     1   \n",
       "1               1    0            0                   1                     0   \n",
       "2               2    0            0                   1                     1   \n",
       "3               1    1            0                   2                     1   \n",
       "4               0    1            2                   1                     2   \n",
       "\n",
       "   XGBoost  pred_mode  y_true  \n",
       "0        1          1       0  \n",
       "1        0          0       2  \n",
       "2        2          2       2  \n",
       "3        0          0       2  \n",
       "4        1          2       2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model_ensemble(df_concat_preds, y_true):\n",
    "    for idx, row in df_concat_preds.iterrows():\n",
    "        pred_mode = row.mode()\n",
    "            # Verificando se a moda é unimodal (apenas um valor)\n",
    "        if len(pred_mode) == 1:\n",
    "            # Se for unimodal, pegue o valor\n",
    "            result = pred_mode.item()\n",
    "            df_concat_preds.loc[idx, 'pred_mode'] = result\n",
    "        else:\n",
    "            # Se for bimodal ou multimodal, trate como necessário (por exemplo, retornando None)\n",
    "            result = row['Logistic Regression']\n",
    "            df_concat_preds.loc[idx, 'pred_mode'] = result\n",
    "\n",
    "    df_concat_preds['pred_mode'] = df_concat_preds['pred_mode'].astype(int)\n",
    "    df_concat_preds['y_true'] = y_true.values\n",
    "\n",
    "    return df_concat_preds\n",
    "\n",
    "\n",
    "df_concat_preds = create_model_ensemble(df_concat_preds, y_true=y_test)\n",
    "\n",
    "df_concat_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_mode\n",
       "1    0.365714\n",
       "2    0.323810\n",
       "0    0.310476\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estou tendo muito falsos positivos para as entre classes\n",
    "# Exemplo: se eu filtrar a classe 0 e dar um value_counts eu consigo observerar \n",
    "#   o seguinte comportamento pred_mode:{2:61%, 0:21%, 1:17%}\n",
    "#   Essa proporção é semelhante a proporção global onde o time visitente(2) tem \n",
    "#   mais dados/chance de ganhar do que o time visitante \n",
    "\n",
    "# Ou sejá, o modelo aprendeu o padrão das proporções, mas não aprendeu padrão pra chegar \n",
    "#   no resultado real para cada classe\n",
    "df_concat_preds[df_concat_preds['y_true']==0]['pred_mode'].value_counts(normalize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acertos_mode\n",
       "False    0.534211\n",
       "True     0.465789\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat_preds['acertos_mode'] = df_concat_preds['pred_mode'] == df_concat_preds['y_true']\n",
    "df_concat_preds['acertos_mode'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reultados: ()\n",
      "    Home_team: ------ 51.0%\n",
      "    Draw: ----------- 31.0%\n",
      "    Away_team: ------ 55.0%\n",
      "    ----------------------------\n"
     ]
    }
   ],
   "source": [
    "metrics_multiclass = get_metrics_multiclass(y_pred=df_concat_preds['pred_mode'], \n",
    "                        y_true=y_test.values)\n",
    "precision_multiclass = get_precision_multiclass(metrics_multiclass=metrics_multiclass)\n",
    "\n",
    "show_print_precision_multiclass(precision_multiclass=precision_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rodada</th>\n",
       "      <th>ht_rank</th>\n",
       "      <th>ht_ls_rank</th>\n",
       "      <th>ht_days_ls_match</th>\n",
       "      <th>ht_points</th>\n",
       "      <th>ht_l_points</th>\n",
       "      <th>ht_l_wavg_points</th>\n",
       "      <th>ht_goals</th>\n",
       "      <th>ht_l_goals</th>\n",
       "      <th>ht_l_wavg_goals</th>\n",
       "      <th>ht_goals_sf</th>\n",
       "      <th>ht_l_goals_sf</th>\n",
       "      <th>ht_l_wavg_goals_sf</th>\n",
       "      <th>ht_wins</th>\n",
       "      <th>ht_draws</th>\n",
       "      <th>ht_losses</th>\n",
       "      <th>ht_win_streak</th>\n",
       "      <th>ht_loss_streak</th>\n",
       "      <th>ht_draw_streak</th>\n",
       "      <th>at_rank</th>\n",
       "      <th>at_ls_rank</th>\n",
       "      <th>at_days_ls_match</th>\n",
       "      <th>at_points</th>\n",
       "      <th>at_l_points</th>\n",
       "      <th>at_l_wavg_points</th>\n",
       "      <th>at_goals</th>\n",
       "      <th>at_l_goals</th>\n",
       "      <th>at_l_wavg_goals</th>\n",
       "      <th>at_goals_sf</th>\n",
       "      <th>at_l_goals_sf</th>\n",
       "      <th>at_l_wavg_goals_sf</th>\n",
       "      <th>at_wins</th>\n",
       "      <th>at_draws</th>\n",
       "      <th>at_losses</th>\n",
       "      <th>at_win_streak</th>\n",
       "      <th>at_loss_streak</th>\n",
       "      <th>at_draw_streak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.239258</td>\n",
       "      <td>19</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>1.005615</td>\n",
       "      <td>24</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1.801025</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.886841</td>\n",
       "      <td>20</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>2.618958</td>\n",
       "      <td>16</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.975342</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>6</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3613</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>10</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.421875</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>10</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.388672</td>\n",
       "      <td>17</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.316406</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rodada  ht_rank  ht_ls_rank  ht_days_ls_match  ht_points  ht_l_points  \\\n",
       "3609       3       11         7.0               3.0          3     1.000000   \n",
       "3610       3       17       -33.0               5.0         11     0.333333   \n",
       "3611       5       10         6.0               6.0          8     2.333333   \n",
       "3612       5       16        13.0               7.0          4     1.000000   \n",
       "3613      13       14         2.0               3.0          7     0.333333   \n",
       "\n",
       "      ht_l_wavg_points  ht_goals  ht_l_goals  ht_l_wavg_goals  ht_goals_sf  \\\n",
       "3609          1.500000         4    1.333333         2.000000            2   \n",
       "3610          0.239258        19    6.333333         1.005615           24   \n",
       "3611          1.750000         6    2.000000         1.250000            4   \n",
       "3612          1.625000         3    1.000000         1.500000            3   \n",
       "3613          0.570312         7    2.333333         0.914062           10   \n",
       "\n",
       "      ht_l_goals_sf  ht_l_wavg_goals_sf  ht_wins  ht_draws  ht_losses  \\\n",
       "3609       0.000000            1.000000        1         0          1   \n",
       "3610       7.333333            1.801025        2         5          7   \n",
       "3611       1.333333            0.875000        2         2          0   \n",
       "3612       0.000000            0.500000        1         1          2   \n",
       "3613       2.333333            1.421875        2         1          5   \n",
       "\n",
       "      ht_win_streak  ht_loss_streak  ht_draw_streak  at_rank  at_ls_rank  \\\n",
       "3609              0               1               0       13         9.0   \n",
       "3610              0               2               0        2        10.0   \n",
       "3611              0               0               1        5         4.0   \n",
       "3612              1               0               0        2        10.0   \n",
       "3613              0               0               1       12         8.0   \n",
       "\n",
       "      at_days_ls_match  at_points  at_l_points  at_l_wavg_points  at_goals  \\\n",
       "3609               3.0          6     2.000000          3.000000         3   \n",
       "3610               4.0         28     3.000000          2.886841        20   \n",
       "3611               6.0          7     1.333333          1.000000         4   \n",
       "3612               7.0          5     1.666667          1.500000         4   \n",
       "3613               2.0          6     0.000000          0.091797        10   \n",
       "\n",
       "      at_l_goals  at_l_wavg_goals  at_goals_sf  at_l_goals_sf  \\\n",
       "3609    1.000000         1.500000            1       0.666667   \n",
       "3610    6.666667         2.618958           16       3.333333   \n",
       "3611    1.333333         0.500000            4       1.666667   \n",
       "3612    1.333333         1.250000            3       1.333333   \n",
       "3613    3.333333         0.388672           17       3.666667   \n",
       "\n",
       "      at_l_wavg_goals_sf  at_wins  at_draws  at_losses  at_win_streak  \\\n",
       "3609            0.500000        2         0          0              2   \n",
       "3610            0.975342        8         4          3              4   \n",
       "3611            1.250000        2         1          1              0   \n",
       "3612            1.000000        1         2          0              0   \n",
       "3613            1.316406        1         3          6              0   \n",
       "\n",
       "      at_loss_streak  at_draw_streak  \n",
       "3609               0               0  \n",
       "3610               0               0  \n",
       "3611               1               0  \n",
       "3612               0               2  \n",
       "3613               3               0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_trans_scaler = get_data_transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempenho dos modelos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>home_precision_%</th>\n",
       "      <th>draw_precision_%</th>\n",
       "      <th>away_precision_%</th>\n",
       "      <th>mdl</th>\n",
       "      <th>accuracy_%</th>\n",
       "      <th>pred</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>59.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>LogisticRegression(max_iter=3000)</td>\n",
       "      <td>55.0</td>\n",
       "      <td>[0, 1, 1, 1, 1, 2, 2, 1, 2, 0, 1, 2, 2, 2, 2, ...</td>\n",
       "      <td>[[0.45800783990714256, 0.1587679354405976, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression tune</td>\n",
       "      <td>63.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>LogisticRegression(C=100, max_iter=3000, solve...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>[0, 1, 1, 1, 1, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, ...</td>\n",
       "      <td>[[0.44454530072935766, 0.13286970028353695, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>43.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>[2, 1, 1, 1, 0, 0, 2, 1, 0, 0, 0, 2, 2, 2, 2, ...</td>\n",
       "      <td>[[0.28, 0.27, 0.45], [0.32, 0.5, 0.18], [0.3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>46.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 2, 2, 2, 2, ...</td>\n",
       "      <td>[[0.4130893268299341, 0.3179242913381855, 0.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>38.0</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 2, 1, 0, 0, 1, 2, 2, 1, 2, ...</td>\n",
       "      <td>[[0.4, 0.2, 0.4], [0.0, 0.6, 0.4], [0.2, 0.4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>44.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>39.0</td>\n",
       "      <td>[0, 1, 2, 1, 2, 2, 2, 2, 1, 0, 1, 2, 1, 0, 2, ...</td>\n",
       "      <td>[[0.6584234863637392, 0.243618284940565, 0.097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>34.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=48, max_featu...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 0, 1, 2, 0, 0, 2, 2, 2, 1, ...</td>\n",
       "      <td>[[0.5333333333333333, 0.13333333333333333, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>MLPClassifier(max_iter=3000)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 2, 1, 0, 0, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>[[0.6949151022103484, 0.05972994180968875, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>[0, 1, 2, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 1, ...</td>\n",
       "      <td>[[0.699464, 0.14289017, 0.15764582], [0.107542...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  algorithm  home_precision_%  draw_precision_%  \\\n",
       "0       Logistic Regression              59.0              29.0   \n",
       "1  Logistic Regression tune              63.0              25.0   \n",
       "2             Random Forest              43.0              36.0   \n",
       "3            Gradient Boost              46.0              31.0   \n",
       "4                       KNN              25.0              53.0   \n",
       "5               Naive Bayes              44.0              29.0   \n",
       "6        Decision Tree (C5)              34.0              42.0   \n",
       "7      Neural Network (MLP)              41.0              42.0   \n",
       "8                   XGBoost              44.0              24.0   \n",
       "\n",
       "   away_precision_%                                                mdl  \\\n",
       "0              72.0                  LogisticRegression(max_iter=3000)   \n",
       "1              68.0  LogisticRegression(C=100, max_iter=3000, solve...   \n",
       "2              60.0  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "3              61.0  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "4              49.0                             KNeighborsClassifier()   \n",
       "5              39.0                                       GaussianNB()   \n",
       "6              53.0  DecisionTreeClassifier(max_depth=48, max_featu...   \n",
       "7              54.0                       MLPClassifier(max_iter=3000)   \n",
       "8              63.0  XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "   accuracy_%                                               pred  \\\n",
       "0        55.0  [0, 1, 1, 1, 1, 2, 2, 1, 2, 0, 1, 2, 2, 2, 2, ...   \n",
       "1        55.0  [0, 1, 1, 1, 1, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, ...   \n",
       "2        45.0  [2, 1, 1, 1, 0, 0, 2, 1, 0, 0, 0, 2, 2, 2, 2, ...   \n",
       "3        46.0  [0, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 2, 2, 2, 2, ...   \n",
       "4        38.0  [0, 1, 1, 0, 1, 0, 2, 1, 0, 0, 1, 2, 2, 1, 2, ...   \n",
       "5        39.0  [0, 1, 2, 1, 2, 2, 2, 2, 1, 0, 1, 2, 1, 0, 2, ...   \n",
       "6        41.0  [0, 0, 1, 1, 1, 1, 0, 1, 2, 0, 0, 2, 2, 2, 1, ...   \n",
       "7        45.0  [0, 1, 1, 1, 1, 0, 2, 1, 0, 0, 0, 1, 0, 1, 1, ...   \n",
       "8        44.0  [0, 1, 2, 1, 1, 2, 2, 0, 1, 0, 1, 0, 2, 2, 1, ...   \n",
       "\n",
       "                                                conf  \n",
       "0  [[0.45800783990714256, 0.1587679354405976, 0.3...  \n",
       "1  [[0.44454530072935766, 0.13286970028353695, 0....  \n",
       "2  [[0.28, 0.27, 0.45], [0.32, 0.5, 0.18], [0.3, ...  \n",
       "3  [[0.4130893268299341, 0.3179242913381855, 0.26...  \n",
       "4  [[0.4, 0.2, 0.4], [0.0, 0.6, 0.4], [0.2, 0.4, ...  \n",
       "5  [[0.6584234863637392, 0.243618284940565, 0.097...  \n",
       "6  [[0.5333333333333333, 0.13333333333333333, 0.3...  \n",
       "7  [[0.6949151022103484, 0.05972994180968875, 0.2...  \n",
       "8  [[0.699464, 0.14289017, 0.15764582], [0.107542...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Desempenho dos modelos')\n",
    "\n",
    "# Modelos com Sem fine tune, só peguei e rodei\n",
    "\n",
    "def pred_models(list_model, X_data_trans_scaler, y_valid):\n",
    "    \n",
    "    list_pred_results = []\n",
    "    for idx, dict_model in enumerate(list_model):\n",
    "        \n",
    "        mdl = dict_model['mdl']\n",
    "        \n",
    "        pred = mdl.predict(X_data_trans_scaler)\n",
    "        conf = mdl.predict_proba(X_data_trans_scaler)\n",
    "        acc = round(accuracy_score(pred, y_valid), 2)\n",
    "\n",
    "        metrics_multiclass = get_metrics_multiclass(y_pred=pred, \n",
    "                        y_true=y_valid.values)\n",
    "        precision_multiclass = get_precision_multiclass(metrics_multiclass=metrics_multiclass)\n",
    "\n",
    "        dict_pred_results = {}\n",
    "        dict_pred_results['algorithm'] = dict_model['algorithm']\n",
    "        dict_pred_results['home_precision_%'] = precision_multiclass.get(2, 0.0) * 100\n",
    "        dict_pred_results['draw_precision_%'] = precision_multiclass.get(0, 0.0) * 100\n",
    "        dict_pred_results['away_precision_%'] = precision_multiclass.get(1, 0.0) * 100\n",
    "        dict_pred_results['mdl'] = mdl \n",
    "        dict_pred_results['accuracy_%'] = acc * 100\n",
    "        dict_pred_results['pred'] = pred\n",
    "        dict_pred_results['conf'] = conf\n",
    "\n",
    "\n",
    "        list_pred_results.append(dict_pred_results)\n",
    "        #print(f'{dict_model[\"algorithm\"]}: {acc}%')\n",
    "\n",
    "    return list_pred_results\n",
    "\n",
    "list_pred_results_valid = pred_models(list_model, X_valid_trans_scaler, y_valid)\n",
    "\n",
    "df_pred_results_valid = pd.DataFrame(list_pred_results_valid)\n",
    "df_pred_results_valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 39)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>home_precision_%</th>\n",
       "      <th>draw_precision_%</th>\n",
       "      <th>away_precision_%</th>\n",
       "      <th>accuracy_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>59.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>46.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>43.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>34.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>44.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              algorithm  home_precision_%  draw_precision_%  away_precision_%  \\\n",
       "0   Logistic Regression              59.0              29.0              72.0   \n",
       "1        Gradient Boost              46.0              31.0              61.0   \n",
       "2         Random Forest              43.0              36.0              60.0   \n",
       "3  Neural Network (MLP)              41.0              42.0              54.0   \n",
       "4               XGBoost              44.0              24.0              63.0   \n",
       "5    Decision Tree (C5)              34.0              42.0              53.0   \n",
       "6           Naive Bayes              44.0              29.0              39.0   \n",
       "7                   KNN              25.0              53.0              49.0   \n",
       "\n",
       "   accuracy_%  \n",
       "0        55.0  \n",
       "1        46.0  \n",
       "2        45.0  \n",
       "3        45.0  \n",
       "4        44.0  \n",
       "5        41.0  \n",
       "6        39.0  \n",
       "7        38.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo linhas indesejadas\n",
    "df_pred_results_valid.drop(index=1, inplace=True)\n",
    "\n",
    "# Melhorando porcentagens\n",
    "#df_pred_results_valid[['home_precision_%','draw_precision_%','away_precision_%','accuracy_%']] = df_pred_results_valid[['home_precision_%','draw_precision_%','away_precision_%','accuracy_%']] * 100\n",
    "df_pred_results_valid[['algorithm',\n",
    "                        'home_precision_%',\n",
    "                        'draw_precision_%',\n",
    "                        'away_precision_%',\n",
    "                        'accuracy_%']].sort_values(by='accuracy_%', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6269, 39)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((220, 37), (220,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_trans_scaler.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pred_results.rename(columns={'draw_precision_%':'tie_precision_%'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia oficial: 0.4535353535353535\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_list_pred_conf_T(list_pred_results, y_true_list:list):\n",
    "    list_pred_conf = []\n",
    "    for pred_results in list_pred_results:\n",
    "        #print(pred_results['algorithm'])\n",
    "\n",
    "        for idx, (y_true, conf) in enumerate(zip(y_true_list, pred_results['conf'])):\n",
    "            y_pred = np.argmax(conf)\n",
    "            conf = round(conf[y_pred] * 100, 0)\n",
    "            #print(f\"y: {y}, y_pred: {y_pred}, conf: {conf}%, is_hit: {y==y_pred}\")\n",
    "\n",
    "            list_pred_conf.append({'idx':idx,\n",
    "                                    'algorithm':pred_results['algorithm'],\n",
    "                                    'y_true':y_true,\n",
    "                                'y_pred':y_pred,\n",
    "                                'conf':conf,\n",
    "                                'is_hit':y_true==y_pred\n",
    "                                })\n",
    "\n",
    "    df_pred_conf = pd.DataFrame(list_pred_conf)\n",
    "\n",
    "    acc_oficial = accuracy_score(y_pred=df_pred_conf['y_pred'].values, \n",
    "                y_true=df_pred_conf['y_true'].values)\n",
    "\n",
    "    print(f'Acuracia oficial: {acc_oficial}')\n",
    "\n",
    "    return list_pred_conf\n",
    "\n",
    "list_pred_conf = create_list_pred_conf_T(list_pred_results_valid, y_true_list=y_valid)\n",
    "df_pred_conf = pd.DataFrame(list_pred_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reultados: (precision_multiclass)\n",
      "    Home_team: ------ 44.0%\n",
      "    Draw: ----------- 35.0%\n",
      "    Away_team: ------ 58.0%\n",
      "    ----------------------------\n"
     ]
    }
   ],
   "source": [
    "metrics_multiclass = get_metrics_multiclass(y_pred=df_pred_conf['y_pred'].values, \n",
    "                         y_true=df_pred_conf['y_true'].values)\n",
    "precision_multiclass = get_precision_multiclass(metrics_multiclass=metrics_multiclass)\n",
    "\n",
    "show_print_precision_multiclass(precision_multiclass=precision_multiclass, algorithm_name='precision_multiclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando modelo / Seleção do modelo\n",
    "\n",
    "\n",
    "### Curva de validação\n",
    "\n",
    "Criar uma curva de validação é uma forma de determinar um valor\n",
    "apropriado para um hiperparâmetro. Uma curva de validação é um gráfico\n",
    "que mostra como o desempenho do modelo responde a mudanças no valor do\n",
    "hiperparâmetro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4359, 37), (4359,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Validation Curve for RandomForestClassifier'}, xlabel='max_depth', ylabel='score'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Curva de aprendizagem\n",
    "from yellowbrick.model_selection import ValidationCurve\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "vc_viz = ValidationCurve(\n",
    "RandomForestClassifier(n_estimators=100),\n",
    "    param_name=\"max_depth\",\n",
    "    param_range=np.arange(1, 11),\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "vc_viz.fit(X=X_train, y=y_train)\n",
    "vc_viz.poof()\n",
    "#fig.savefig(\"images/mlpr_1101.png\", dpi=300)\n",
    "\n",
    "# O gráfico mostra as instâncias de treinamento e a pontuação para\n",
    "# validação cruzada à medida que criamos modelos com mais amostras. \n",
    "# Se a pontuação da validação cruzada continuar a subir, por exemplo, poderá ser\n",
    "# um sinal de que mais dados ajudariam o modelo a ter um melhor desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Learning Curve for RandomForestClassifier'}, xlabel='Training Instances', ylabel='Score'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yellowbrick.model_selection import LearningCurve\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "lc3_viz = LearningCurve(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=100),\n",
    "        cv=10,\n",
    "    )\n",
    "\n",
    "lc3_viz.fit(X_train, y_train)\n",
    "lc3_viz.poof()\n",
    "#fig.savefig(\"images/mlpr_1102.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_hit\n",
       "False    0.540984\n",
       "True     0.459016\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_pred_conf[df_pred_conf['conf']>=40]['is_hit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrando por IDX espesifico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.59, 45.35)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_confIDX = df_pred_conf#[df_pred_conf['idx']==278]\n",
    "\n",
    "df_selected_pred_confIDX = df_pred_confIDX[df_pred_confIDX['conf']>=80]#['is_hit'].value_counts(normalize=True)\n",
    "\n",
    "y_pred_crop = df_selected_pred_confIDX['y_pred'].values\n",
    "y_true_crop = df_selected_pred_confIDX['y_true'].values\n",
    "\n",
    "acc_crop = accuracy_score(y_pred=y_pred_crop, \n",
    "               y_true=y_true_crop)\n",
    "\n",
    "acc_oficial = accuracy_score(y_pred=df_pred_confIDX['y_pred'].values, \n",
    "               y_true=df_pred_confIDX['y_true'].values)\n",
    "\n",
    "round(acc_crop*100, 2), round(acc_oficial*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>conf</th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>38</td>\n",
       "      <td>KNN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>104</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>106</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>112</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>114</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>138</td>\n",
       "      <td>KNN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>157</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>189</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>193</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>198</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>199</td>\n",
       "      <td>KNN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>214</td>\n",
       "      <td>KNN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>51</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>76</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>80</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>86</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>87</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>101</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>108</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>113</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>114</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>118</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>124</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>137</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>162</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>167</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>172</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>178</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>186</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>188</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>199</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>219</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>10</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>28</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>29</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>30</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>63</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>65</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>69</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>89</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>132</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>150</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>203</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>211</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>212</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>219</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>9</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>80</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>102</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>122</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>124</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>129</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>133</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>158</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>194</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>195</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>197</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>201</td>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>46</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>51</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>102</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>141</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>207</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idx             algorithm  y_true  y_pred   conf  is_hit\n",
       "918    38                   KNN       2       0  100.0   False\n",
       "984   104                   KNN       0       0   80.0    True\n",
       "986   106                   KNN       0       0  100.0    True\n",
       "992   112                   KNN       1       0   80.0   False\n",
       "994   114                   KNN       1       0   80.0   False\n",
       "1018  138                   KNN       2       0   80.0   False\n",
       "1037  157                   KNN       0       0   80.0    True\n",
       "1069  189                   KNN       1       0   80.0   False\n",
       "1073  193                   KNN       0       0  100.0    True\n",
       "1078  198                   KNN       1       0   80.0   False\n",
       "1079  199                   KNN       2       0   80.0   False\n",
       "1094  214                   KNN       2       0   80.0   False\n",
       "1151   51           Naive Bayes       0       0   80.0    True\n",
       "1176   76           Naive Bayes       0       0   98.0    True\n",
       "1180   80           Naive Bayes       1       0   80.0   False\n",
       "1186   86           Naive Bayes       1       0   98.0   False\n",
       "1187   87           Naive Bayes       2       0   82.0   False\n",
       "1201  101           Naive Bayes       1       0   96.0   False\n",
       "1208  108           Naive Bayes       2       0   97.0   False\n",
       "1213  113           Naive Bayes       0       0   98.0    True\n",
       "1214  114           Naive Bayes       1       0   80.0   False\n",
       "1218  118           Naive Bayes       2       0   97.0   False\n",
       "1224  124           Naive Bayes       0       0   93.0    True\n",
       "1237  137           Naive Bayes       0       0   80.0    True\n",
       "1262  162           Naive Bayes       1       0   99.0   False\n",
       "1267  167           Naive Bayes       1       0   99.0   False\n",
       "1272  172           Naive Bayes       2       0   98.0   False\n",
       "1278  178           Naive Bayes       2       0   97.0   False\n",
       "1286  186           Naive Bayes       1       0   98.0   False\n",
       "1288  188           Naive Bayes       0       0   98.0    True\n",
       "1299  199           Naive Bayes       2       0   98.0   False\n",
       "1319  219           Naive Bayes       0       0   97.0    True\n",
       "1330   10    Decision Tree (C5)       0       0   90.0    True\n",
       "1348   28    Decision Tree (C5)       1       0  100.0   False\n",
       "1349   29    Decision Tree (C5)       0       0   82.0    True\n",
       "1350   30    Decision Tree (C5)       2       0   80.0   False\n",
       "1383   63    Decision Tree (C5)       2       0   90.0   False\n",
       "1385   65    Decision Tree (C5)       1       0   86.0   False\n",
       "1389   69    Decision Tree (C5)       2       0   83.0   False\n",
       "1409   89    Decision Tree (C5)       2       0  100.0   False\n",
       "1452  132    Decision Tree (C5)       0       0   83.0    True\n",
       "1470  150    Decision Tree (C5)       2       0   90.0   False\n",
       "1523  203    Decision Tree (C5)       0       0  100.0    True\n",
       "1531  211    Decision Tree (C5)       2       0   90.0   False\n",
       "1532  212    Decision Tree (C5)       2       0   88.0   False\n",
       "1539  219    Decision Tree (C5)       0       0   83.0    True\n",
       "1549    9  Neural Network (MLP)       0       0   91.0    True\n",
       "1620   80  Neural Network (MLP)       1       0   98.0   False\n",
       "1642  102  Neural Network (MLP)       2       0   87.0   False\n",
       "1662  122  Neural Network (MLP)       2       0   81.0   False\n",
       "1664  124  Neural Network (MLP)       0       0   93.0    True\n",
       "1669  129  Neural Network (MLP)       2       0   93.0   False\n",
       "1673  133  Neural Network (MLP)       2       0   92.0   False\n",
       "1698  158  Neural Network (MLP)       2       0   90.0   False\n",
       "1734  194  Neural Network (MLP)       1       0   85.0   False\n",
       "1735  195  Neural Network (MLP)       1       0   92.0   False\n",
       "1737  197  Neural Network (MLP)       1       0   83.0   False\n",
       "1741  201  Neural Network (MLP)       0       0   84.0    True\n",
       "1806   46               XGBoost       2       0   82.0   False\n",
       "1811   51               XGBoost       0       0   81.0    True\n",
       "1862  102               XGBoost       2       0   85.0   False\n",
       "1901  141               XGBoost       2       0   80.0   False\n",
       "1967  207               XGBoost       1       0   84.0   False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected_pred_confIDX[df_selected_pred_confIDX['y_pred']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>conf</th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>215</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>216</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>217</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>218</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>219</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>69.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1980 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      idx            algorithm  y_true  y_pred  conf  is_hit\n",
       "0       0  Logistic Regression       2       0  46.0   False\n",
       "1       1  Logistic Regression       0       1  62.0   False\n",
       "2       2  Logistic Regression       0       1  46.0   False\n",
       "3       3  Logistic Regression       0       1  72.0   False\n",
       "4       4  Logistic Regression       2       1  49.0   False\n",
       "...   ...                  ...     ...     ...   ...     ...\n",
       "1975  215              XGBoost       0       1  59.0   False\n",
       "1976  216              XGBoost       0       0  48.0    True\n",
       "1977  217              XGBoost       1       1  69.0    True\n",
       "1978  218              XGBoost       1       2  72.0   False\n",
       "1979  219              XGBoost       0       2  69.0   False\n",
       "\n",
       "[1980 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_confIDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_concat_preds_valid = concat_preds(list_model=list_pred_results)\n",
    "#\n",
    "#df_ensemble_valid = create_model_ensemble(df_concat_preds=df_concat_preds_valid,\n",
    "#                                          y_true=y_valid)\n",
    "#\n",
    "#df_ensemble_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ensemble_valid['acertos_mode'] = df_ensemble_valid['pred_mode'] == df_ensemble_valid['y_true']\n",
    "#df_ensemble_valid['acertos_mode'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reultados (precisão)\n",
      "          \n",
      "    Home_team: ------ 48.0%\n",
      "    Draw: ----------- 53.0%\n",
      "    Away_team: ------ 34.0%\n"
     ]
    }
   ],
   "source": [
    "metrics_multiclass = get_metrics_multiclass(y_pred=df_concat_preds_valid['pred_mode'], y_true=y_valid.values)\n",
    "\n",
    "precision_multiclass=get_precision_multiclass(metrics_multiclass=metrics_multiclass)\n",
    "show_print_precision_multiclass(precision_multiclass=precision_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reultados (precisão)\n",
      "          \n",
      "    Home_team: ------ 49.42%\n",
      "    Draw: ----------- 26.64%\n",
      "    Away_team: ------ 23.95%\n"
     ]
    }
   ],
   "source": [
    "# Este é a proporção de distribuição REAL dos dados\n",
    "show_print_precision_multiclass(precision_multiclass=df['winner'].value_counts(normalize=True).to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando apostas com o melhor modelo usando dados de validação\n",
    "\n",
    "1- Realizar apostas\n",
    "    - Mandar df com os dados para realizar a previsão\n",
    "    - Retornar df com predições e confiança do modelo\n",
    "\n",
    "2- Checar resultados\n",
    "    - Obter todas as metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para realizar apostas com os dados de validação seria legal \n",
    "\n",
    "df_jogos_apostas = df_valid.copy()#.iloc[0:6].copy()\n",
    "\n",
    "y_jogos_apostas = df_jogos_apostas['winner']\n",
    "df_jogos_apostas.drop(columns='winner', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_jogos_apostas['y_conf'] = list_preds['y_pred']\n",
    "#df_jogos_apostas['y_conf'] = list_preds['y_conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def open_list_preds_conf(list_pred_results):\n",
    "    \"\"\"\n",
    "    Explora a lista de predições com confianças e retorna uma lista com as predições com mais confiança\n",
    "    \"\"\"\n",
    "\n",
    "    # Vai selecionar os modelos com a confiança maior que o trash\n",
    "    list_pred_conf = []\n",
    "    for pred_results in list_pred_results:\n",
    "        #print(pred_results['algorithm'])\n",
    "\n",
    "        for idx, conf in enumerate(pred_results['conf']):\n",
    "            y_pred = np.argmax(conf)\n",
    "            conf = round(conf[y_pred] * 100, 0)\n",
    "            #print(f\"y: {y}, y_pred: {y_pred}, conf: {conf}%, is_hit: {y==y_pred}\")\n",
    "\n",
    "            list_pred_conf.append({'idx':idx,\n",
    "                                    'algorithm':pred_results['algorithm'],\n",
    "                                'y_pred':y_pred,\n",
    "                                'conf':conf,\n",
    "                                })\n",
    "\n",
    "    df_pred_conf = pd.DataFrame(list_pred_conf)\n",
    "\n",
    "    list_preds = {'y_pred':[], 'y_conf':[]}\n",
    "    for idx in df_pred_conf['idx'].unique():\n",
    "        threshold = 80\n",
    "\n",
    "        query = df_pred_conf[(df_pred_conf['idx']==3) & (df_pred_conf['conf']>=threshold)]\n",
    "\n",
    "        y_pred = query['y_pred'].mode().iloc[0]\n",
    "        y_conf = query['conf'].mean()\n",
    "\n",
    "        list_preds['y_pred'].append(y_pred)\n",
    "        list_preds['y_conf'].append(y_conf)\n",
    "\n",
    "    return list_preds\n",
    "\n",
    "def realizar_aposta(df_apostas):\n",
    "    \"\"\"\n",
    "    Realiza a predição de apostas esportivas\n",
    "\n",
    "    Retorna uma lista contendo o resultado da predição\n",
    "\n",
    "    Realiza a predição e obtem a confiança de varios modelos e por fim retorna uma lista com as predições com mais confiança\n",
    "    \"\"\"\n",
    "    # Tratar dados \n",
    "\n",
    "    X_data_trans_scaler = get_data_transform(df_apostas, rfe, get_y_true=False)\n",
    "\n",
    "\n",
    "    # Realiza o a predição com varios modelos\n",
    "    list_pred_results = []\n",
    "    for idx, dict_model in enumerate(list_model):\n",
    "        mdl = dict_model['mdl']\n",
    "\n",
    "        pred = mdl.predict(X_data_trans_scaler)\n",
    "        conf = mdl.predict_proba(X_data_trans_scaler)\n",
    "        \n",
    "        dict_pred_results = {}\n",
    "        dict_pred_results['algorithm'] = dict_model['algorithm']\n",
    "        dict_pred_results['home_team_precision_%'] = None\n",
    "        dict_pred_results['draw_precision_%'] = None\n",
    "        dict_pred_results['away_team_precision_%'] = None\n",
    "        dict_pred_results['mdl'] = mdl \n",
    "        dict_pred_results['accuracy'] = None\n",
    "        dict_pred_results['pred'] = pred\n",
    "        dict_pred_results['conf'] = conf\n",
    "\n",
    "\n",
    "        list_pred_results.append(dict_pred_results)\n",
    "        #print(f'{dict_model[\"algorithm\"]}: {acc}%')\n",
    "\n",
    "        \n",
    "    list_preds = open_list_preds_conf(list_pred_results)\n",
    "\n",
    "    df_apostas['y_pred'] = list_preds['y_pred']\n",
    "    df_apostas['y_conf'] = list_preds['y_conf']\n",
    "\n",
    "    #df_apostas['conf'] = dict_pred_results['conf']\n",
    "\n",
    "    return df_apostas\n",
    "\n",
    "\n",
    "def checar_apostas(df_apostas_with_preds, y_true):\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=df_apostas_with_preds['y_pred'], \n",
    "               y_true=y_true)\n",
    "    \n",
    "    df_apostas_with_preds['y_true'] = y_true\n",
    "    df_apostas_with_preds['is_hit'] = df_apostas_with_preds['y_pred'] == y_true\n",
    "    \n",
    "    \n",
    "    print(f'Acuracia de acertos: {round(accuracy*100, 2)}')\n",
    "\n",
    "    return df_apostas_with_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>ht_rank</th>\n",
       "      <th>ht_ls_rank</th>\n",
       "      <th>ht_days_ls_match</th>\n",
       "      <th>ht_points</th>\n",
       "      <th>ht_l_points</th>\n",
       "      <th>ht_l_wavg_points</th>\n",
       "      <th>ht_goals</th>\n",
       "      <th>ht_l_goals</th>\n",
       "      <th>ht_l_wavg_goals</th>\n",
       "      <th>ht_goals_sf</th>\n",
       "      <th>ht_l_goals_sf</th>\n",
       "      <th>ht_l_wavg_goals_sf</th>\n",
       "      <th>ht_wins</th>\n",
       "      <th>ht_draws</th>\n",
       "      <th>ht_losses</th>\n",
       "      <th>ht_win_streak</th>\n",
       "      <th>ht_loss_streak</th>\n",
       "      <th>ht_draw_streak</th>\n",
       "      <th>at_rank</th>\n",
       "      <th>at_ls_rank</th>\n",
       "      <th>at_days_ls_match</th>\n",
       "      <th>at_points</th>\n",
       "      <th>at_l_points</th>\n",
       "      <th>at_l_wavg_points</th>\n",
       "      <th>at_goals</th>\n",
       "      <th>at_l_goals</th>\n",
       "      <th>at_l_wavg_goals</th>\n",
       "      <th>at_goals_sf</th>\n",
       "      <th>at_l_goals_sf</th>\n",
       "      <th>at_l_wavg_goals_sf</th>\n",
       "      <th>at_wins</th>\n",
       "      <th>at_draws</th>\n",
       "      <th>at_losses</th>\n",
       "      <th>at_win_streak</th>\n",
       "      <th>at_loss_streak</th>\n",
       "      <th>at_draw_streak</th>\n",
       "      <th>ls_winner_-33</th>\n",
       "      <th>ls_winner_AWAY_TEAM</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>14</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.406250</td>\n",
       "      <td>6</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>18</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.946533</td>\n",
       "      <td>13</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.410767</td>\n",
       "      <td>16</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.190674</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.909912</td>\n",
       "      <td>25</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>1.126465</td>\n",
       "      <td>13</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>1.214478</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.713745</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.782715</td>\n",
       "      <td>18</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.216064</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.740479</td>\n",
       "      <td>15</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>21</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.341797</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2023</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.450007</td>\n",
       "      <td>25</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>2.281223</td>\n",
       "      <td>37</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.337611</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.638788</td>\n",
       "      <td>31</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>0.864850</td>\n",
       "      <td>27</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.602856</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>2024</td>\n",
       "      <td>16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>2024</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>7</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.539062</td>\n",
       "      <td>14</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.101562</td>\n",
       "      <td>7</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      season  ht_rank  ht_ls_rank  ht_days_ls_match  ht_points  ht_l_points  \\\n",
       "380     2023        8         3.0               7.0          3     1.000000   \n",
       "381     2023        5        11.0               9.0         18     2.000000   \n",
       "382     2023        9         2.0               7.0         21     1.333333   \n",
       "383     2023        7         7.0               7.0         20     1.333333   \n",
       "384     2023       18        13.0              12.0         27     0.666667   \n",
       "...      ...      ...         ...               ...        ...          ...   \n",
       "2738    2024       16        15.0             -33.0          0     0.000000   \n",
       "2739    2024        1         5.0               2.0          3     1.000000   \n",
       "2740    2024        9         3.0               3.0          2     0.666667   \n",
       "2741    2024        3         7.0             -33.0          0     0.000000   \n",
       "2742    2024       17         2.0               2.0          6     0.000000   \n",
       "\n",
       "      ht_l_wavg_points  ht_goals  ht_l_goals  ht_l_wavg_goals  ht_goals_sf  \\\n",
       "380           3.000000         3    1.000000         3.000000            0   \n",
       "381           2.250000        14    4.666667         1.406250            6   \n",
       "382           0.946533        13    4.333333         0.410767           16   \n",
       "383           0.713745        18    6.000000         0.782715           18   \n",
       "384           0.450007        25    8.333333         2.281223           37   \n",
       "...                ...       ...         ...              ...          ...   \n",
       "2738          0.000000         0    0.000000         0.000000            0   \n",
       "2739          1.500000         3    1.000000         1.500000            3   \n",
       "2740          1.000000         1    0.333333         0.500000            1   \n",
       "2741          0.000000         0    0.000000         0.000000            0   \n",
       "2742          0.281250         5    1.666667         0.656250            7   \n",
       "\n",
       "      ht_l_goals_sf  ht_l_wavg_goals_sf  ht_wins  ht_draws  ht_losses  \\\n",
       "380        1.000000            0.000000        1         0          0   \n",
       "381        2.333333            0.593750        6         0          1   \n",
       "382        3.333333            1.190674        6         3          5   \n",
       "383        4.333333            1.216064        6         2          6   \n",
       "384       10.000000            3.337611        6         9         11   \n",
       "...             ...                 ...      ...       ...        ...   \n",
       "2738       0.000000            0.000000        0         0          0   \n",
       "2739       0.666667            1.500000        1         0          1   \n",
       "2740       0.333333            0.500000        0         2          0   \n",
       "2741       0.000000            0.000000        0         0          0   \n",
       "2742       1.333333            1.687500        2         0          4   \n",
       "\n",
       "      ht_win_streak  ht_loss_streak  ht_draw_streak  at_rank  at_ls_rank  \\\n",
       "380               1               0               0        7         7.0   \n",
       "381               1               0               0       20        10.0   \n",
       "382               0               1               0        1         1.0   \n",
       "383               0               1               0       16       -33.0   \n",
       "384               0               1               0       11         9.0   \n",
       "...             ...             ...             ...      ...         ...   \n",
       "2738              0               0               0       17         2.0   \n",
       "2739              1               0               0       11       -33.0   \n",
       "2740              0               0               2        8        14.0   \n",
       "2741              0               0               0       15        12.0   \n",
       "2742              0               3               0        1         5.0   \n",
       "\n",
       "      at_days_ls_match  at_points  at_l_points  at_l_wavg_points  at_goals  \\\n",
       "380                7.0          3     1.000000          3.000000         2   \n",
       "381                9.0          4     1.333333          1.625000         7   \n",
       "382                7.0         24     0.666667          0.909912        25   \n",
       "383                8.0         13     0.333333          0.740479        15   \n",
       "384               12.0         35     2.333333          1.638788        31   \n",
       "...                ...        ...          ...               ...       ...   \n",
       "2738             -33.0          0     0.000000          0.000000         0   \n",
       "2739               3.0          4     1.333333          2.000000         3   \n",
       "2740               3.0          4     1.333333          2.000000         4   \n",
       "2741             -33.0          0     0.000000          0.000000         0   \n",
       "2742               2.0         16     2.333333          2.539062        14   \n",
       "\n",
       "      at_l_goals  at_l_wavg_goals  at_goals_sf  at_l_goals_sf  \\\n",
       "380     0.666667         2.000000            0       0.000000   \n",
       "381     2.333333         1.375000           18       4.666667   \n",
       "382     8.333333         1.126465           13       6.333333   \n",
       "383     5.000000         1.009766           21       5.000000   \n",
       "384    10.333333         0.864850           27       7.000000   \n",
       "...          ...              ...          ...            ...   \n",
       "2738    0.000000         0.000000            0       0.000000   \n",
       "2739    1.000000         1.500000            1       0.333333   \n",
       "2740    1.333333         2.000000            3       1.000000   \n",
       "2741    0.000000         0.000000            0       0.000000   \n",
       "2742    4.666667         1.101562            7       3.000000   \n",
       "\n",
       "      at_l_wavg_goals_sf  at_wins  at_draws  at_losses  at_win_streak  \\\n",
       "380             0.000000        1         0          0              1   \n",
       "381             2.062500        1         1          5              1   \n",
       "382             1.214478        6         6          2              0   \n",
       "383             1.341797        3         4          7              0   \n",
       "384             0.602856        9         8          9              0   \n",
       "...                  ...      ...       ...        ...            ...   \n",
       "2738            0.000000        0         0          0              0   \n",
       "2739            0.500000        1         1          0              1   \n",
       "2740            1.500000        1         1          0              0   \n",
       "2741            0.000000        0         0          0              0   \n",
       "2742            0.289062        5         1          2              2   \n",
       "\n",
       "      at_loss_streak  at_draw_streak  ls_winner_-33  ls_winner_AWAY_TEAM  \\\n",
       "380                0               0          False                 True   \n",
       "381                0               0          False                 True   \n",
       "382                0               2          False                 True   \n",
       "383                0               1          False                 True   \n",
       "384                0               1          False                 True   \n",
       "...              ...             ...            ...                  ...   \n",
       "2738               0               0          False                 True   \n",
       "2739               0               0          False                 True   \n",
       "2740               0               1          False                 True   \n",
       "2741               0               0          False                 True   \n",
       "2742               0               0          False                 True   \n",
       "\n",
       "      y_pred  y_conf  \n",
       "380        2    80.0  \n",
       "381        2    80.0  \n",
       "382        2    80.0  \n",
       "383        2    80.0  \n",
       "384        2    80.0  \n",
       "...      ...     ...  \n",
       "2738       2    80.0  \n",
       "2739       2    80.0  \n",
       "2740       2    80.0  \n",
       "2741       2    80.0  \n",
       "2742       2    80.0  \n",
       "\n",
       "[463 rows x 41 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jogos_apostas = realizar_aposta(df_apostas=df_jogos_apostas)\n",
    "\n",
    "#df_jogos_apostas = checar_apostas(df_apostas_with_preds=df_jogos_apostas,\n",
    "#               y_true=y_jogos_apostas)\n",
    "\n",
    "\n",
    "df_jogos_apostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>ht_rank</th>\n",
       "      <th>ht_ls_rank</th>\n",
       "      <th>ht_days_ls_match</th>\n",
       "      <th>ht_points</th>\n",
       "      <th>ht_l_points</th>\n",
       "      <th>ht_l_wavg_points</th>\n",
       "      <th>ht_goals</th>\n",
       "      <th>ht_l_goals</th>\n",
       "      <th>ht_l_wavg_goals</th>\n",
       "      <th>ht_goals_sf</th>\n",
       "      <th>ht_l_goals_sf</th>\n",
       "      <th>ht_l_wavg_goals_sf</th>\n",
       "      <th>ht_wins</th>\n",
       "      <th>ht_draws</th>\n",
       "      <th>ht_losses</th>\n",
       "      <th>ht_win_streak</th>\n",
       "      <th>ht_loss_streak</th>\n",
       "      <th>ht_draw_streak</th>\n",
       "      <th>at_rank</th>\n",
       "      <th>at_ls_rank</th>\n",
       "      <th>at_days_ls_match</th>\n",
       "      <th>at_points</th>\n",
       "      <th>at_l_points</th>\n",
       "      <th>at_l_wavg_points</th>\n",
       "      <th>at_goals</th>\n",
       "      <th>at_l_goals</th>\n",
       "      <th>at_l_wavg_goals</th>\n",
       "      <th>at_goals_sf</th>\n",
       "      <th>at_l_goals_sf</th>\n",
       "      <th>at_l_wavg_goals_sf</th>\n",
       "      <th>at_wins</th>\n",
       "      <th>at_draws</th>\n",
       "      <th>at_losses</th>\n",
       "      <th>at_win_streak</th>\n",
       "      <th>at_loss_streak</th>\n",
       "      <th>at_draw_streak</th>\n",
       "      <th>ls_winner_-33</th>\n",
       "      <th>ls_winner_AWAY_TEAM</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>14</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.406250</td>\n",
       "      <td>6</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>18</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.946533</td>\n",
       "      <td>13</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.410767</td>\n",
       "      <td>16</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.190674</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.909912</td>\n",
       "      <td>25</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>1.126465</td>\n",
       "      <td>13</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>1.214478</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.713745</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.782715</td>\n",
       "      <td>18</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.216064</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.740479</td>\n",
       "      <td>15</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>21</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.341797</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2023</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.450007</td>\n",
       "      <td>25</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>2.281223</td>\n",
       "      <td>37</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.337611</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.638788</td>\n",
       "      <td>31</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>0.864850</td>\n",
       "      <td>27</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.602856</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>2024</td>\n",
       "      <td>16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>2024</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>7</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.539062</td>\n",
       "      <td>14</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.101562</td>\n",
       "      <td>7</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      season  ht_rank  ht_ls_rank  ht_days_ls_match  ht_points  ht_l_points  \\\n",
       "380     2023        8         3.0               7.0          3     1.000000   \n",
       "381     2023        5        11.0               9.0         18     2.000000   \n",
       "382     2023        9         2.0               7.0         21     1.333333   \n",
       "383     2023        7         7.0               7.0         20     1.333333   \n",
       "384     2023       18        13.0              12.0         27     0.666667   \n",
       "...      ...      ...         ...               ...        ...          ...   \n",
       "2738    2024       16        15.0             -33.0          0     0.000000   \n",
       "2739    2024        1         5.0               2.0          3     1.000000   \n",
       "2740    2024        9         3.0               3.0          2     0.666667   \n",
       "2741    2024        3         7.0             -33.0          0     0.000000   \n",
       "2742    2024       17         2.0               2.0          6     0.000000   \n",
       "\n",
       "      ht_l_wavg_points  ht_goals  ht_l_goals  ht_l_wavg_goals  ht_goals_sf  \\\n",
       "380           3.000000         3    1.000000         3.000000            0   \n",
       "381           2.250000        14    4.666667         1.406250            6   \n",
       "382           0.946533        13    4.333333         0.410767           16   \n",
       "383           0.713745        18    6.000000         0.782715           18   \n",
       "384           0.450007        25    8.333333         2.281223           37   \n",
       "...                ...       ...         ...              ...          ...   \n",
       "2738          0.000000         0    0.000000         0.000000            0   \n",
       "2739          1.500000         3    1.000000         1.500000            3   \n",
       "2740          1.000000         1    0.333333         0.500000            1   \n",
       "2741          0.000000         0    0.000000         0.000000            0   \n",
       "2742          0.281250         5    1.666667         0.656250            7   \n",
       "\n",
       "      ht_l_goals_sf  ht_l_wavg_goals_sf  ht_wins  ht_draws  ht_losses  \\\n",
       "380        1.000000            0.000000        1         0          0   \n",
       "381        2.333333            0.593750        6         0          1   \n",
       "382        3.333333            1.190674        6         3          5   \n",
       "383        4.333333            1.216064        6         2          6   \n",
       "384       10.000000            3.337611        6         9         11   \n",
       "...             ...                 ...      ...       ...        ...   \n",
       "2738       0.000000            0.000000        0         0          0   \n",
       "2739       0.666667            1.500000        1         0          1   \n",
       "2740       0.333333            0.500000        0         2          0   \n",
       "2741       0.000000            0.000000        0         0          0   \n",
       "2742       1.333333            1.687500        2         0          4   \n",
       "\n",
       "      ht_win_streak  ht_loss_streak  ht_draw_streak  at_rank  at_ls_rank  \\\n",
       "380               1               0               0        7         7.0   \n",
       "381               1               0               0       20        10.0   \n",
       "382               0               1               0        1         1.0   \n",
       "383               0               1               0       16       -33.0   \n",
       "384               0               1               0       11         9.0   \n",
       "...             ...             ...             ...      ...         ...   \n",
       "2738              0               0               0       17         2.0   \n",
       "2739              1               0               0       11       -33.0   \n",
       "2740              0               0               2        8        14.0   \n",
       "2741              0               0               0       15        12.0   \n",
       "2742              0               3               0        1         5.0   \n",
       "\n",
       "      at_days_ls_match  at_points  at_l_points  at_l_wavg_points  at_goals  \\\n",
       "380                7.0          3     1.000000          3.000000         2   \n",
       "381                9.0          4     1.333333          1.625000         7   \n",
       "382                7.0         24     0.666667          0.909912        25   \n",
       "383                8.0         13     0.333333          0.740479        15   \n",
       "384               12.0         35     2.333333          1.638788        31   \n",
       "...                ...        ...          ...               ...       ...   \n",
       "2738             -33.0          0     0.000000          0.000000         0   \n",
       "2739               3.0          4     1.333333          2.000000         3   \n",
       "2740               3.0          4     1.333333          2.000000         4   \n",
       "2741             -33.0          0     0.000000          0.000000         0   \n",
       "2742               2.0         16     2.333333          2.539062        14   \n",
       "\n",
       "      at_l_goals  at_l_wavg_goals  at_goals_sf  at_l_goals_sf  \\\n",
       "380     0.666667         2.000000            0       0.000000   \n",
       "381     2.333333         1.375000           18       4.666667   \n",
       "382     8.333333         1.126465           13       6.333333   \n",
       "383     5.000000         1.009766           21       5.000000   \n",
       "384    10.333333         0.864850           27       7.000000   \n",
       "...          ...              ...          ...            ...   \n",
       "2738    0.000000         0.000000            0       0.000000   \n",
       "2739    1.000000         1.500000            1       0.333333   \n",
       "2740    1.333333         2.000000            3       1.000000   \n",
       "2741    0.000000         0.000000            0       0.000000   \n",
       "2742    4.666667         1.101562            7       3.000000   \n",
       "\n",
       "      at_l_wavg_goals_sf  at_wins  at_draws  at_losses  at_win_streak  \\\n",
       "380             0.000000        1         0          0              1   \n",
       "381             2.062500        1         1          5              1   \n",
       "382             1.214478        6         6          2              0   \n",
       "383             1.341797        3         4          7              0   \n",
       "384             0.602856        9         8          9              0   \n",
       "...                  ...      ...       ...        ...            ...   \n",
       "2738            0.000000        0         0          0              0   \n",
       "2739            0.500000        1         1          0              1   \n",
       "2740            1.500000        1         1          0              0   \n",
       "2741            0.000000        0         0          0              0   \n",
       "2742            0.289062        5         1          2              2   \n",
       "\n",
       "      at_loss_streak  at_draw_streak  ls_winner_-33  ls_winner_AWAY_TEAM  \\\n",
       "380                0               0          False                 True   \n",
       "381                0               0          False                 True   \n",
       "382                0               2          False                 True   \n",
       "383                0               1          False                 True   \n",
       "384                0               1          False                 True   \n",
       "...              ...             ...            ...                  ...   \n",
       "2738               0               0          False                 True   \n",
       "2739               0               0          False                 True   \n",
       "2740               0               1          False                 True   \n",
       "2741               0               0          False                 True   \n",
       "2742               0               0          False                 True   \n",
       "\n",
       "      y_pred  y_true  is_hit  \n",
       "380        2       2    True  \n",
       "381        2       2    True  \n",
       "382        2       0   False  \n",
       "383        2       2    True  \n",
       "384        2       2    True  \n",
       "...      ...     ...     ...  \n",
       "2738       2       2    True  \n",
       "2739       2       2    True  \n",
       "2740       2       2    True  \n",
       "2741       2       2    True  \n",
       "2742       2       1   False  \n",
       "\n",
       "[463 rows x 42 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jogos_apostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>home_team_precision_%</th>\n",
       "      <th>draw_precision_%</th>\n",
       "      <th>away_precision_%</th>\n",
       "      <th>mdl</th>\n",
       "      <th>accuracy_%</th>\n",
       "      <th>pred</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>54.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>LogisticRegression(max_iter=3000)</td>\n",
       "      <td>47.0</td>\n",
       "      <td>[0, 2, 1, 2, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[[0.5615647230496207, 0.18085231112892586, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression tune</td>\n",
       "      <td>58.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>LogisticRegression(C=100, max_iter=3000, solve...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>[0, 2, 1, 2, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[[0.591601910855013, 0.1353547197542159, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>28.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 1, 1, 0, 2, 1, 1, 1, 0, 2, ...</td>\n",
       "      <td>[[0.29, 0.39, 0.32], [0.5, 0.21, 0.29], [0.41,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>32.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[0, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 2, ...</td>\n",
       "      <td>[[0.5259835639489234, 0.36598580178585954, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>35.0</td>\n",
       "      <td>[0, 2, 1, 2, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0.8, 0.2, 0.0], [0.4, 0.0, 0.6], [0.2, 0.6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>41.0</td>\n",
       "      <td>[0, 0, 1, 2, 1, 2, 1, 0, 1, 0, 2, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[0.8983123019655864, 0.07262937039954137, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=48, max_featu...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>[1, 1, 0, 1, 0, 2, 0, 0, 1, 0, 1, 2, 1, 1, 2, ...</td>\n",
       "      <td>[[0.35294117647058826, 0.47058823529411764, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neural Network (MLP)</td>\n",
       "      <td>36.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>MLPClassifier(max_iter=3000)</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[0, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0.7818775653652936, 0.2100199997372594, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[1, 2, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[[0.14951096, 0.63839555, 0.2120935], [0.39460...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  algorithm  home_team_precision_%  draw_precision_%  \\\n",
       "0       Logistic Regression                   54.0              50.0   \n",
       "1  Logistic Regression tune                   58.0              53.0   \n",
       "2             Random Forest                   28.0              50.0   \n",
       "3            Gradient Boost                   32.0              41.0   \n",
       "4                       KNN                   30.0              43.0   \n",
       "5               Naive Bayes                   41.0              40.0   \n",
       "6        Decision Tree (C5)                   26.0              38.0   \n",
       "7      Neural Network (MLP)                   36.0              57.0   \n",
       "8                   XGBoost                   38.0              42.0   \n",
       "\n",
       "   away_precision_%                                                mdl  \\\n",
       "0              32.0                  LogisticRegression(max_iter=3000)   \n",
       "1              31.0  LogisticRegression(C=100, max_iter=3000, solve...   \n",
       "2              37.0  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "3              53.0  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "4              34.0                             KNeighborsClassifier()   \n",
       "5              43.0                                       GaussianNB()   \n",
       "6              45.0  DecisionTreeClassifier(max_depth=48, max_featu...   \n",
       "7              31.0                       MLPClassifier(max_iter=3000)   \n",
       "8              43.0  XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "   accuracy_%                                               pred  \\\n",
       "0        47.0  [0, 2, 1, 2, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "1        49.0  [0, 2, 1, 2, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "2        36.0  [1, 0, 0, 0, 1, 0, 1, 1, 0, 2, 1, 1, 1, 0, 2, ...   \n",
       "3        40.0  [0, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 2, ...   \n",
       "4        35.0  [0, 2, 1, 2, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, ...   \n",
       "5        41.0  [0, 0, 1, 2, 1, 2, 1, 0, 1, 0, 2, 1, 1, 1, 1, ...   \n",
       "6        34.0  [1, 1, 0, 1, 0, 2, 0, 0, 1, 0, 1, 2, 1, 1, 2, ...   \n",
       "7        40.0  [0, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8        40.0  [1, 2, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, ...   \n",
       "\n",
       "                                                conf  \n",
       "0  [[0.5615647230496207, 0.18085231112892586, 0.2...  \n",
       "1  [[0.591601910855013, 0.1353547197542159, 0.273...  \n",
       "2  [[0.29, 0.39, 0.32], [0.5, 0.21, 0.29], [0.41,...  \n",
       "3  [[0.5259835639489234, 0.36598580178585954, 0.1...  \n",
       "4  [[0.8, 0.2, 0.0], [0.4, 0.0, 0.6], [0.2, 0.6, ...  \n",
       "5  [[0.8983123019655864, 0.07262937039954137, 0.0...  \n",
       "6  [[0.35294117647058826, 0.47058823529411764, 0....  \n",
       "7  [[0.7818775653652936, 0.2100199997372594, 0.00...  \n",
       "8  [[0.14951096, 0.63839555, 0.2120935], [0.39460...  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list_pred_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>ht_rank</th>\n",
       "      <th>ht_ls_rank</th>\n",
       "      <th>ht_days_ls_match</th>\n",
       "      <th>ht_points</th>\n",
       "      <th>ht_l_points</th>\n",
       "      <th>ht_l_wavg_points</th>\n",
       "      <th>ht_goals</th>\n",
       "      <th>ht_l_goals</th>\n",
       "      <th>ht_l_wavg_goals</th>\n",
       "      <th>ht_goals_sf</th>\n",
       "      <th>ht_l_goals_sf</th>\n",
       "      <th>ht_l_wavg_goals_sf</th>\n",
       "      <th>ht_wins</th>\n",
       "      <th>ht_draws</th>\n",
       "      <th>ht_losses</th>\n",
       "      <th>ht_win_streak</th>\n",
       "      <th>ht_loss_streak</th>\n",
       "      <th>ht_draw_streak</th>\n",
       "      <th>at_rank</th>\n",
       "      <th>at_ls_rank</th>\n",
       "      <th>at_days_ls_match</th>\n",
       "      <th>at_points</th>\n",
       "      <th>at_l_points</th>\n",
       "      <th>at_l_wavg_points</th>\n",
       "      <th>at_goals</th>\n",
       "      <th>at_l_goals</th>\n",
       "      <th>at_l_wavg_goals</th>\n",
       "      <th>at_goals_sf</th>\n",
       "      <th>at_l_goals_sf</th>\n",
       "      <th>at_l_wavg_goals_sf</th>\n",
       "      <th>at_wins</th>\n",
       "      <th>at_draws</th>\n",
       "      <th>at_losses</th>\n",
       "      <th>at_win_streak</th>\n",
       "      <th>at_loss_streak</th>\n",
       "      <th>at_draw_streak</th>\n",
       "      <th>ls_winner_-33</th>\n",
       "      <th>ls_winner_AWAY_TEAM</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>14</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.406250</td>\n",
       "      <td>6</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>18</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.946533</td>\n",
       "      <td>13</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.410767</td>\n",
       "      <td>16</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.190674</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.909912</td>\n",
       "      <td>25</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>1.126465</td>\n",
       "      <td>13</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>1.214478</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.713745</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.782715</td>\n",
       "      <td>18</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.216064</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.740479</td>\n",
       "      <td>15</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>21</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.341797</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2023</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.450007</td>\n",
       "      <td>25</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>2.281223</td>\n",
       "      <td>37</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.337611</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.638788</td>\n",
       "      <td>31</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>0.864850</td>\n",
       "      <td>27</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.602856</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>2024</td>\n",
       "      <td>16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>2024</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>7</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.539062</td>\n",
       "      <td>14</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.101562</td>\n",
       "      <td>7</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      season  ht_rank  ht_ls_rank  ht_days_ls_match  ht_points  ht_l_points  \\\n",
       "380     2023        8         3.0               7.0          3     1.000000   \n",
       "381     2023        5        11.0               9.0         18     2.000000   \n",
       "382     2023        9         2.0               7.0         21     1.333333   \n",
       "383     2023        7         7.0               7.0         20     1.333333   \n",
       "384     2023       18        13.0              12.0         27     0.666667   \n",
       "...      ...      ...         ...               ...        ...          ...   \n",
       "2738    2024       16        15.0             -33.0          0     0.000000   \n",
       "2739    2024        1         5.0               2.0          3     1.000000   \n",
       "2740    2024        9         3.0               3.0          2     0.666667   \n",
       "2741    2024        3         7.0             -33.0          0     0.000000   \n",
       "2742    2024       17         2.0               2.0          6     0.000000   \n",
       "\n",
       "      ht_l_wavg_points  ht_goals  ht_l_goals  ht_l_wavg_goals  ht_goals_sf  \\\n",
       "380           3.000000         3    1.000000         3.000000            0   \n",
       "381           2.250000        14    4.666667         1.406250            6   \n",
       "382           0.946533        13    4.333333         0.410767           16   \n",
       "383           0.713745        18    6.000000         0.782715           18   \n",
       "384           0.450007        25    8.333333         2.281223           37   \n",
       "...                ...       ...         ...              ...          ...   \n",
       "2738          0.000000         0    0.000000         0.000000            0   \n",
       "2739          1.500000         3    1.000000         1.500000            3   \n",
       "2740          1.000000         1    0.333333         0.500000            1   \n",
       "2741          0.000000         0    0.000000         0.000000            0   \n",
       "2742          0.281250         5    1.666667         0.656250            7   \n",
       "\n",
       "      ht_l_goals_sf  ht_l_wavg_goals_sf  ht_wins  ht_draws  ht_losses  \\\n",
       "380        1.000000            0.000000        1         0          0   \n",
       "381        2.333333            0.593750        6         0          1   \n",
       "382        3.333333            1.190674        6         3          5   \n",
       "383        4.333333            1.216064        6         2          6   \n",
       "384       10.000000            3.337611        6         9         11   \n",
       "...             ...                 ...      ...       ...        ...   \n",
       "2738       0.000000            0.000000        0         0          0   \n",
       "2739       0.666667            1.500000        1         0          1   \n",
       "2740       0.333333            0.500000        0         2          0   \n",
       "2741       0.000000            0.000000        0         0          0   \n",
       "2742       1.333333            1.687500        2         0          4   \n",
       "\n",
       "      ht_win_streak  ht_loss_streak  ht_draw_streak  at_rank  at_ls_rank  \\\n",
       "380               1               0               0        7         7.0   \n",
       "381               1               0               0       20        10.0   \n",
       "382               0               1               0        1         1.0   \n",
       "383               0               1               0       16       -33.0   \n",
       "384               0               1               0       11         9.0   \n",
       "...             ...             ...             ...      ...         ...   \n",
       "2738              0               0               0       17         2.0   \n",
       "2739              1               0               0       11       -33.0   \n",
       "2740              0               0               2        8        14.0   \n",
       "2741              0               0               0       15        12.0   \n",
       "2742              0               3               0        1         5.0   \n",
       "\n",
       "      at_days_ls_match  at_points  at_l_points  at_l_wavg_points  at_goals  \\\n",
       "380                7.0          3     1.000000          3.000000         2   \n",
       "381                9.0          4     1.333333          1.625000         7   \n",
       "382                7.0         24     0.666667          0.909912        25   \n",
       "383                8.0         13     0.333333          0.740479        15   \n",
       "384               12.0         35     2.333333          1.638788        31   \n",
       "...                ...        ...          ...               ...       ...   \n",
       "2738             -33.0          0     0.000000          0.000000         0   \n",
       "2739               3.0          4     1.333333          2.000000         3   \n",
       "2740               3.0          4     1.333333          2.000000         4   \n",
       "2741             -33.0          0     0.000000          0.000000         0   \n",
       "2742               2.0         16     2.333333          2.539062        14   \n",
       "\n",
       "      at_l_goals  at_l_wavg_goals  at_goals_sf  at_l_goals_sf  \\\n",
       "380     0.666667         2.000000            0       0.000000   \n",
       "381     2.333333         1.375000           18       4.666667   \n",
       "382     8.333333         1.126465           13       6.333333   \n",
       "383     5.000000         1.009766           21       5.000000   \n",
       "384    10.333333         0.864850           27       7.000000   \n",
       "...          ...              ...          ...            ...   \n",
       "2738    0.000000         0.000000            0       0.000000   \n",
       "2739    1.000000         1.500000            1       0.333333   \n",
       "2740    1.333333         2.000000            3       1.000000   \n",
       "2741    0.000000         0.000000            0       0.000000   \n",
       "2742    4.666667         1.101562            7       3.000000   \n",
       "\n",
       "      at_l_wavg_goals_sf  at_wins  at_draws  at_losses  at_win_streak  \\\n",
       "380             0.000000        1         0          0              1   \n",
       "381             2.062500        1         1          5              1   \n",
       "382             1.214478        6         6          2              0   \n",
       "383             1.341797        3         4          7              0   \n",
       "384             0.602856        9         8          9              0   \n",
       "...                  ...      ...       ...        ...            ...   \n",
       "2738            0.000000        0         0          0              0   \n",
       "2739            0.500000        1         1          0              1   \n",
       "2740            1.500000        1         1          0              0   \n",
       "2741            0.000000        0         0          0              0   \n",
       "2742            0.289062        5         1          2              2   \n",
       "\n",
       "      at_loss_streak  at_draw_streak  ls_winner_-33  ls_winner_AWAY_TEAM  \\\n",
       "380                0               0          False                 True   \n",
       "381                0               0          False                 True   \n",
       "382                0               2          False                 True   \n",
       "383                0               1          False                 True   \n",
       "384                0               1          False                 True   \n",
       "...              ...             ...            ...                  ...   \n",
       "2738               0               0          False                 True   \n",
       "2739               0               0          False                 True   \n",
       "2740               0               1          False                 True   \n",
       "2741               0               0          False                 True   \n",
       "2742               0               0          False                 True   \n",
       "\n",
       "      y_pred  y_true  is_hit  \n",
       "380        2       2    True  \n",
       "381        2       2    True  \n",
       "382        2       0   False  \n",
       "383        2       2    True  \n",
       "384        2       2    True  \n",
       "...      ...     ...     ...  \n",
       "2738       2       2    True  \n",
       "2739       2       2    True  \n",
       "2740       2       2    True  \n",
       "2741       2       2    True  \n",
       "2742       2       1   False  \n",
       "\n",
       "[463 rows x 42 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pred_results = realizar_aposta(df_jogos_apostas)\n",
    "\n",
    "pd.DataFrame(list_pred_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m list_pred_conf \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_list_pred_conf_T\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_pred_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_jogos_apostas\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[144], line 8\u001b[0m, in \u001b[0;36mcreate_list_pred_conf_T\u001b[0;34m(list_pred_results, y_true_list)\u001b[0m\n\u001b[1;32m      4\u001b[0m list_pred_conf \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pred_results \u001b[38;5;129;01min\u001b[39;00m list_pred_results:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#print(pred_results['algorithm'])\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (y_true, conf) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(y_true_list, \u001b[43mpred_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)):\n\u001b[1;32m      9\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(conf)\n\u001b[1;32m     10\u001b[0m         conf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(conf[y_pred] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "list_pred_conf = create_list_pred_conf_T(list_pred_results, y_true_list=y_jogos_apostas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m list_pred_results \u001b[38;5;241m=\u001b[39m realizar_aposta(df_jogos_apostas)\n\u001b[1;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(list_pred_results)\n\u001b[0;32m----> 5\u001b[0m list_pred_conf \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_list_pred_conf_T\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_pred_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_jogos_apostas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df_pred_conf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(list_pred_conf)\n\u001b[1;32m      7\u001b[0m df_pred_conf\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[144], line 8\u001b[0m, in \u001b[0;36mcreate_list_pred_conf_T\u001b[0;34m(list_pred_results, y_true_list)\u001b[0m\n\u001b[1;32m      4\u001b[0m list_pred_conf \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pred_results \u001b[38;5;129;01min\u001b[39;00m list_pred_results:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#print(pred_results['algorithm'])\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (y_true, conf) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(y_true_list, \u001b[43mpred_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)):\n\u001b[1;32m      9\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(conf)\n\u001b[1;32m     10\u001b[0m         conf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(conf[y_pred] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "df_pred_conf = pd.DataFrame(list_pred_conf)\n",
    "df_pred_conf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['winner'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_jogos_apostas_trans_scaler, y_jogos_apostas \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_jogos_apostas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrfe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m list_pred_results \u001b[38;5;241m=\u001b[39m pred_models(list_model, X_jogos_apostas_trans_scaler, y_jogos_apostas)\n\u001b[1;32m      5\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(list_pred_results)\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[128], line 5\u001b[0m, in \u001b[0;36mget_data_transform\u001b[0;34m(df_valid, rfe, get_y_true)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data_transform\u001b[39m(df_valid, rfe, get_y_true\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Recebe dataframe e retorna o dado pronto para ser realizado a predição\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     X_valid \u001b[38;5;241m=\u001b[39m \u001b[43mdf_valid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwinner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseason\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     X_valid_trans \u001b[38;5;241m=\u001b[39m rfe\u001b[38;5;241m.\u001b[39mtransform(X_valid)\n\u001b[1;32m      9\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n",
      "File \u001b[0;32m/media/guilherme/ssd_m2_data/My_projects/Jogos/bet-soccer/venv/lib/python3.10/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/guilherme/ssd_m2_data/My_projects/Jogos/bet-soccer/venv/lib/python3.10/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/media/guilherme/ssd_m2_data/My_projects/Jogos/bet-soccer/venv/lib/python3.10/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/media/guilherme/ssd_m2_data/My_projects/Jogos/bet-soccer/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['winner'] not found in axis\""
     ]
    }
   ],
   "source": [
    "X_jogos_apostas_trans_scaler, y_jogos_apostas = get_data_transform(df_jogos_apostas, rfe)\n",
    "\n",
    "list_pred_results = pred_models(list_model, X_jogos_apostas_trans_scaler, y_jogos_apostas)\n",
    "\n",
    "pd.DataFrame(list_pred_results).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia oficial: 0.5925925925925926\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>conf</th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression 1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression 1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>69.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression 1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression 1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>69.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression 1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               algorithm  y_true  y_pred  conf  is_hit\n",
       "0  Logistic Regression 1       2       2  46.0    True\n",
       "1  Logistic Regression 1       2       2  69.0    True\n",
       "2  Logistic Regression 1       0       1  46.0   False\n",
       "3  Logistic Regression 1       2       2  69.0    True\n",
       "4  Logistic Regression 1       2       2  41.0    True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pred_conf = create_list_pred_conf_T(list_pred_results, y_true_list=y_jogos_apostas)\n",
    "df_pred_conf = pd.DataFrame(list_pred_conf)\n",
    "df_pred_conf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>conf</th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>3</td>\n",
       "      <td>KNN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>3</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>3</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idx           algorithm  y_true  y_pred  conf  is_hit\n",
       "1855    3                 KNN       2       2  80.0    True\n",
       "2318    3         Naive Bayes       2       2  80.0    True\n",
       "2781    3  Decision Tree (C5)       2       2  88.0    True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 80\n",
    "\n",
    "df_pred_confIDX = df_pred_conf[df_pred_conf['idx']==3]\n",
    "\n",
    "df_selected_pred_confIDX = df_pred_confIDX[df_pred_confIDX['conf']>=threshold]#['is_hit'].value_counts(normalize=True)\n",
    "\n",
    "#y_pred_crop = df_selected_pred_confIDX['y_pred'].values\n",
    "#y_true_crop = df_selected_pred_confIDX['y_true'].values\n",
    "#\n",
    "#acc_crop = accuracy_score(y_pred=y_pred_crop, \n",
    "#               y_true=y_true_crop)\n",
    "#\n",
    "#acc_oficial = accuracy_score(y_pred=df_pred_confIDX['y_pred'].values, \n",
    "#               y_true=df_pred_confIDX['y_true'].values)\n",
    "#\n",
    "#round(acc_crop*100, 2), round(acc_oficial*100, 2)\n",
    "\n",
    "df_selected_pred_confIDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>conf</th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>3</td>\n",
       "      <td>KNN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>3</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>3</td>\n",
       "      <td>Decision Tree (C5)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idx           algorithm  y_true  y_pred  conf  is_hit\n",
       "1855    3                 KNN       2       2  80.0    True\n",
       "2318    3         Naive Bayes       2       2  80.0    True\n",
       "2781    3  Decision Tree (C5)       2       2  88.0    True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>winner</th>\n",
       "      <th>ht_rank</th>\n",
       "      <th>ht_ls_rank</th>\n",
       "      <th>ht_days_ls_match</th>\n",
       "      <th>ht_points</th>\n",
       "      <th>ht_l_points</th>\n",
       "      <th>ht_l_wavg_points</th>\n",
       "      <th>ht_goals</th>\n",
       "      <th>ht_l_goals</th>\n",
       "      <th>ht_l_wavg_goals</th>\n",
       "      <th>ht_goals_sf</th>\n",
       "      <th>ht_l_goals_sf</th>\n",
       "      <th>ht_l_wavg_goals_sf</th>\n",
       "      <th>ht_wins</th>\n",
       "      <th>ht_draws</th>\n",
       "      <th>ht_losses</th>\n",
       "      <th>ht_win_streak</th>\n",
       "      <th>ht_loss_streak</th>\n",
       "      <th>ht_draw_streak</th>\n",
       "      <th>at_rank</th>\n",
       "      <th>at_ls_rank</th>\n",
       "      <th>at_days_ls_match</th>\n",
       "      <th>at_points</th>\n",
       "      <th>at_l_points</th>\n",
       "      <th>at_l_wavg_points</th>\n",
       "      <th>at_goals</th>\n",
       "      <th>at_l_goals</th>\n",
       "      <th>at_l_wavg_goals</th>\n",
       "      <th>at_goals_sf</th>\n",
       "      <th>at_l_goals_sf</th>\n",
       "      <th>at_l_wavg_goals_sf</th>\n",
       "      <th>at_wins</th>\n",
       "      <th>at_draws</th>\n",
       "      <th>at_losses</th>\n",
       "      <th>at_win_streak</th>\n",
       "      <th>at_loss_streak</th>\n",
       "      <th>at_draw_streak</th>\n",
       "      <th>ls_winner_-33</th>\n",
       "      <th>ls_winner_AWAY_TEAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>14</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.406250</td>\n",
       "      <td>6</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>18</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.946533</td>\n",
       "      <td>13</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.410767</td>\n",
       "      <td>16</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.190674</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.909912</td>\n",
       "      <td>25</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>1.126465</td>\n",
       "      <td>13</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>1.214478</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.713745</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.782715</td>\n",
       "      <td>18</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.216064</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.740479</td>\n",
       "      <td>15</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>21</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.341797</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.450007</td>\n",
       "      <td>25</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>2.281223</td>\n",
       "      <td>37</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.337611</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.638788</td>\n",
       "      <td>31</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>0.864850</td>\n",
       "      <td>27</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.602856</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.306939</td>\n",
       "      <td>62</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>3.000835</td>\n",
       "      <td>32</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.737921</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.731951</td>\n",
       "      <td>49</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>2.210298</td>\n",
       "      <td>43</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.362353</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  winner  ht_rank  ht_ls_rank  ht_days_ls_match  ht_points  \\\n",
       "380    2023       2        8         3.0               7.0          3   \n",
       "381    2023       2        5        11.0               9.0         18   \n",
       "382    2023       0        9         2.0               7.0         21   \n",
       "383    2023       2        7         7.0               7.0         20   \n",
       "384    2023       2       18        13.0              12.0         27   \n",
       "385    2023       2        1         1.0               3.0         66   \n",
       "\n",
       "     ht_l_points  ht_l_wavg_points  ht_goals  ht_l_goals  ht_l_wavg_goals  \\\n",
       "380     1.000000          3.000000         3    1.000000         3.000000   \n",
       "381     2.000000          2.250000        14    4.666667         1.406250   \n",
       "382     1.333333          0.946533        13    4.333333         0.410767   \n",
       "383     1.333333          0.713745        18    6.000000         0.782715   \n",
       "384     0.666667          0.450007        25    8.333333         2.281223   \n",
       "385     2.333333          2.306939        62   20.666667         3.000835   \n",
       "\n",
       "     ht_goals_sf  ht_l_goals_sf  ht_l_wavg_goals_sf  ht_wins  ht_draws  \\\n",
       "380            0       1.000000            0.000000        1         0   \n",
       "381            6       2.333333            0.593750        6         0   \n",
       "382           16       3.333333            1.190674        6         3   \n",
       "383           18       4.333333            1.216064        6         2   \n",
       "384           37      10.000000            3.337611        6         9   \n",
       "385           32      13.333333            0.737921       19         9   \n",
       "\n",
       "     ht_losses  ht_win_streak  ht_loss_streak  ht_draw_streak  at_rank  \\\n",
       "380          0              1               0               0        7   \n",
       "381          1              1               0               0       20   \n",
       "382          5              0               1               0        1   \n",
       "383          6              0               1               0       16   \n",
       "384         11              0               1               0       11   \n",
       "385          8              1               0               0        8   \n",
       "\n",
       "     at_ls_rank  at_days_ls_match  at_points  at_l_points  at_l_wavg_points  \\\n",
       "380         7.0               7.0          3     1.000000          3.000000   \n",
       "381        10.0               9.0          4     1.333333          1.625000   \n",
       "382         1.0               7.0         24     0.666667          0.909912   \n",
       "383       -33.0               8.0         13     0.333333          0.740479   \n",
       "384         9.0              12.0         35     2.333333          1.638788   \n",
       "385         3.0               4.0         56     3.000000          2.731951   \n",
       "\n",
       "     at_goals  at_l_goals  at_l_wavg_goals  at_goals_sf  at_l_goals_sf  \\\n",
       "380         2    0.666667         2.000000            0       0.000000   \n",
       "381         7    2.333333         1.375000           18       4.666667   \n",
       "382        25    8.333333         1.126465           13       6.333333   \n",
       "383        15    5.000000         1.009766           21       5.000000   \n",
       "384        31   10.333333         0.864850           27       7.000000   \n",
       "385        49   16.333333         2.210298           43      11.000000   \n",
       "\n",
       "     at_l_wavg_goals_sf  at_wins  at_draws  at_losses  at_win_streak  \\\n",
       "380            0.000000        1         0          0              1   \n",
       "381            2.062500        1         1          5              1   \n",
       "382            1.214478        6         6          2              0   \n",
       "383            1.341797        3         4          7              0   \n",
       "384            0.602856        9         8          9              0   \n",
       "385            0.362353       16         8         12              3   \n",
       "\n",
       "     at_loss_streak  at_draw_streak  ls_winner_-33  ls_winner_AWAY_TEAM  \n",
       "380               0               0          False                 True  \n",
       "381               0               0          False                 True  \n",
       "382               0               2          False                 True  \n",
       "383               0               1          False                 True  \n",
       "384               0               1          False                 True  \n",
       "385               0               0          False                 True  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jogos_apostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reultados (precisão)\n",
      "          \n",
      "    Home_team: ------ 71.0%\n",
      "    Draw: ----------- 0.0%\n",
      "    Away_team: ------ 0%\n"
     ]
    }
   ],
   "source": [
    "metrics_multiclass = get_metrics_multiclass(y_pred=df_pred_conf['y_pred'].values, \n",
    "                         y_true=df_pred_conf['y_true'].values)\n",
    "precision_multiclass = get_precision_multiclass(metrics_multiclass=metrics_multiclass)\n",
    "\n",
    "show_print_precision_multiclass(precision_multiclass=precision_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>winner</th>\n",
       "      <th>ht_rank</th>\n",
       "      <th>ht_ls_rank</th>\n",
       "      <th>ht_days_ls_match</th>\n",
       "      <th>ht_points</th>\n",
       "      <th>ht_l_points</th>\n",
       "      <th>ht_l_wavg_points</th>\n",
       "      <th>ht_goals</th>\n",
       "      <th>ht_l_goals</th>\n",
       "      <th>ht_l_wavg_goals</th>\n",
       "      <th>ht_goals_sf</th>\n",
       "      <th>ht_l_goals_sf</th>\n",
       "      <th>ht_l_wavg_goals_sf</th>\n",
       "      <th>ht_wins</th>\n",
       "      <th>ht_draws</th>\n",
       "      <th>ht_losses</th>\n",
       "      <th>ht_win_streak</th>\n",
       "      <th>ht_loss_streak</th>\n",
       "      <th>ht_draw_streak</th>\n",
       "      <th>at_rank</th>\n",
       "      <th>at_ls_rank</th>\n",
       "      <th>at_days_ls_match</th>\n",
       "      <th>at_points</th>\n",
       "      <th>at_l_points</th>\n",
       "      <th>at_l_wavg_points</th>\n",
       "      <th>at_goals</th>\n",
       "      <th>at_l_goals</th>\n",
       "      <th>at_l_wavg_goals</th>\n",
       "      <th>at_goals_sf</th>\n",
       "      <th>at_l_goals_sf</th>\n",
       "      <th>at_l_wavg_goals_sf</th>\n",
       "      <th>at_wins</th>\n",
       "      <th>at_draws</th>\n",
       "      <th>at_losses</th>\n",
       "      <th>at_win_streak</th>\n",
       "      <th>at_loss_streak</th>\n",
       "      <th>at_draw_streak</th>\n",
       "      <th>ls_winner_-33</th>\n",
       "      <th>ls_winner_AWAY_TEAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>14</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.406250</td>\n",
       "      <td>6</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>18</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.946533</td>\n",
       "      <td>13</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.410767</td>\n",
       "      <td>16</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.190674</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.909912</td>\n",
       "      <td>25</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>1.126465</td>\n",
       "      <td>13</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>1.214478</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.713745</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.782715</td>\n",
       "      <td>18</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.216064</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.740479</td>\n",
       "      <td>15</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>21</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.341797</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.450007</td>\n",
       "      <td>25</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>2.281223</td>\n",
       "      <td>37</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.337611</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.638788</td>\n",
       "      <td>31</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>0.864850</td>\n",
       "      <td>27</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.602856</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.306939</td>\n",
       "      <td>62</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>3.000835</td>\n",
       "      <td>32</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.737921</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.731951</td>\n",
       "      <td>49</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>2.210298</td>\n",
       "      <td>43</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.362353</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  winner  ht_rank  ht_ls_rank  ht_days_ls_match  ht_points  \\\n",
       "380    2023       2        8         3.0               7.0          3   \n",
       "381    2023       2        5        11.0               9.0         18   \n",
       "382    2023       0        9         2.0               7.0         21   \n",
       "383    2023       2        7         7.0               7.0         20   \n",
       "384    2023       2       18        13.0              12.0         27   \n",
       "385    2023       2        1         1.0               3.0         66   \n",
       "\n",
       "     ht_l_points  ht_l_wavg_points  ht_goals  ht_l_goals  ht_l_wavg_goals  \\\n",
       "380     1.000000          3.000000         3    1.000000         3.000000   \n",
       "381     2.000000          2.250000        14    4.666667         1.406250   \n",
       "382     1.333333          0.946533        13    4.333333         0.410767   \n",
       "383     1.333333          0.713745        18    6.000000         0.782715   \n",
       "384     0.666667          0.450007        25    8.333333         2.281223   \n",
       "385     2.333333          2.306939        62   20.666667         3.000835   \n",
       "\n",
       "     ht_goals_sf  ht_l_goals_sf  ht_l_wavg_goals_sf  ht_wins  ht_draws  \\\n",
       "380            0       1.000000            0.000000        1         0   \n",
       "381            6       2.333333            0.593750        6         0   \n",
       "382           16       3.333333            1.190674        6         3   \n",
       "383           18       4.333333            1.216064        6         2   \n",
       "384           37      10.000000            3.337611        6         9   \n",
       "385           32      13.333333            0.737921       19         9   \n",
       "\n",
       "     ht_losses  ht_win_streak  ht_loss_streak  ht_draw_streak  at_rank  \\\n",
       "380          0              1               0               0        7   \n",
       "381          1              1               0               0       20   \n",
       "382          5              0               1               0        1   \n",
       "383          6              0               1               0       16   \n",
       "384         11              0               1               0       11   \n",
       "385          8              1               0               0        8   \n",
       "\n",
       "     at_ls_rank  at_days_ls_match  at_points  at_l_points  at_l_wavg_points  \\\n",
       "380         7.0               7.0          3     1.000000          3.000000   \n",
       "381        10.0               9.0          4     1.333333          1.625000   \n",
       "382         1.0               7.0         24     0.666667          0.909912   \n",
       "383       -33.0               8.0         13     0.333333          0.740479   \n",
       "384         9.0              12.0         35     2.333333          1.638788   \n",
       "385         3.0               4.0         56     3.000000          2.731951   \n",
       "\n",
       "     at_goals  at_l_goals  at_l_wavg_goals  at_goals_sf  at_l_goals_sf  \\\n",
       "380         2    0.666667         2.000000            0       0.000000   \n",
       "381         7    2.333333         1.375000           18       4.666667   \n",
       "382        25    8.333333         1.126465           13       6.333333   \n",
       "383        15    5.000000         1.009766           21       5.000000   \n",
       "384        31   10.333333         0.864850           27       7.000000   \n",
       "385        49   16.333333         2.210298           43      11.000000   \n",
       "\n",
       "     at_l_wavg_goals_sf  at_wins  at_draws  at_losses  at_win_streak  \\\n",
       "380            0.000000        1         0          0              1   \n",
       "381            2.062500        1         1          5              1   \n",
       "382            1.214478        6         6          2              0   \n",
       "383            1.341797        3         4          7              0   \n",
       "384            0.602856        9         8          9              0   \n",
       "385            0.362353       16         8         12              3   \n",
       "\n",
       "     at_loss_streak  at_draw_streak  ls_winner_-33  ls_winner_AWAY_TEAM  \n",
       "380               0               0          False                 True  \n",
       "381               0               0          False                 True  \n",
       "382               0               2          False                 True  \n",
       "383               0               1          False                 True  \n",
       "384               0               1          False                 True  \n",
       "385               0               0          False                 True  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar uma função que retorne a predição com o vencedor e a confiança\n",
    "\n",
    "df_jogos_apostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'end' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mend\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'end' is not defined"
     ]
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "dict_param: {'n_estimators': np.int64(317), 'max_depth': np.int64(43), 'min_samples_split': np.int64(17), 'min_samples_leaf': np.int64(9), 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}\n",
      "metric: 0.4903508771929825\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 3.9886\n",
      "Function value obtained: -0.4904\n",
      "Current minimum: -0.4904\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "dict_param: {'n_estimators': np.int64(76), 'max_depth': np.int64(17), 'min_samples_split': np.int64(11), 'min_samples_leaf': np.int64(8), 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}\n",
      "metric: 0.4763157894736842\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 1.4695\n",
      "Function value obtained: -0.4763\n",
      "Current minimum: -0.4904\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "dict_param: {'n_estimators': np.int64(202), 'max_depth': np.int64(34), 'min_samples_split': np.int64(9), 'min_samples_leaf': np.int64(10), 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}\n",
      "metric: 0.49122807017543857\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 4.7024\n",
      "Function value obtained: -0.4912\n",
      "Current minimum: -0.4912\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "dict_param: {'n_estimators': np.int64(410), 'max_depth': np.int64(28), 'min_samples_split': np.int64(14), 'min_samples_leaf': np.int64(7), 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}\n",
      "metric: 0.48596491228070177\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 10.7024\n",
      "Function value obtained: -0.4860\n",
      "Current minimum: -0.4912\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "dict_param: {'n_estimators': np.int64(98), 'max_depth': np.int64(26), 'min_samples_split': np.int64(5), 'min_samples_leaf': np.int64(8), 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}\n",
      "metric: 0.4789473684210526\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 1.5682\n",
      "Function value obtained: -0.4789\n",
      "Current minimum: -0.4912\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "dict_param: {'n_estimators': np.int64(117), 'max_depth': np.int64(15), 'min_samples_split': np.int64(9), 'min_samples_leaf': np.int64(9), 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}\n",
      "metric: 0.4921052631578947\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 3.0269\n",
      "Function value obtained: -0.4921\n",
      "Current minimum: -0.4921\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "dict_param: {'n_estimators': np.int64(95), 'max_depth': np.int64(49), 'min_samples_split': np.int64(14), 'min_samples_leaf': np.int64(3), 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}\n",
      "metric: 0.47368421052631576\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 3.2424\n",
      "Function value obtained: -0.4737\n",
      "Current minimum: -0.4921\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "dict_param: {'n_estimators': np.int64(196), 'max_depth': np.int64(7), 'min_samples_split': np.int64(13), 'min_samples_leaf': np.int64(10), 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}\n",
      "metric: 0.4710526315789474\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 2.4019\n",
      "Function value obtained: -0.4711\n",
      "Current minimum: -0.4921\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "dict_param: {'n_estimators': np.int64(312), 'max_depth': np.int64(24), 'min_samples_split': np.int64(11), 'min_samples_leaf': np.int64(7), 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}\n",
      "metric: 0.48947368421052634\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 7.1485\n",
      "Function value obtained: -0.4895\n",
      "Current minimum: -0.4921\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "dict_param: {'n_estimators': np.int64(400), 'max_depth': np.int64(48), 'min_samples_split': np.int64(14), 'min_samples_leaf': np.int64(1), 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}\n",
      "metric: 0.4842105263157895\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 12.3746\n",
      "Function value obtained: -0.4842\n",
      "Current minimum: -0.4921\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "dict_param: {'n_estimators': np.int64(209), 'max_depth': np.int64(5), 'min_samples_split': np.int64(9), 'min_samples_leaf': np.int64(1), 'max_features': np.str_('sqrt'), 'bootstrap': np.False_, 'criterion': np.str_('entropy')}\n",
      "metric: 0.4614035087719298\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.5687\n",
      "Function value obtained: -0.4614\n",
      "Current minimum: -0.4921\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "dict_param: {'n_estimators': np.int64(197), 'max_depth': np.int64(36), 'min_samples_split': np.int64(2), 'min_samples_leaf': np.int64(5), 'max_features': np.str_('log2'), 'bootstrap': np.True_, 'criterion': np.str_('gini')}\n",
      "metric: 0.493859649122807\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.1273\n",
      "Function value obtained: -0.4939\n",
      "Current minimum: -0.4939\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "dict_param: {'n_estimators': np.int64(478), 'max_depth': np.int64(17), 'min_samples_split': np.int64(20), 'min_samples_leaf': np.int64(1), 'max_features': np.str_('log2'), 'bootstrap': np.True_, 'criterion': np.str_('entropy')}\n",
      "metric: 0.4921052631578947\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.6657\n",
      "Function value obtained: -0.4921\n",
      "Current minimum: -0.4939\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "dict_param: {'n_estimators': np.int64(500), 'max_depth': np.int64(34), 'min_samples_split': np.int64(20), 'min_samples_leaf': np.int64(5), 'max_features': np.str_('log2'), 'bootstrap': np.True_, 'criterion': np.str_('entropy')}\n",
      "metric: 0.49122807017543857\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.5784\n",
      "Function value obtained: -0.4912\n",
      "Current minimum: -0.4939\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "dict_param: {'n_estimators': np.int64(271), 'max_depth': np.int64(50), 'min_samples_split': np.int64(2), 'min_samples_leaf': np.int64(3), 'max_features': np.str_('log2'), 'bootstrap': np.True_, 'criterion': np.str_('entropy')}\n",
      "metric: 0.48157894736842105\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.8590\n",
      "Function value obtained: -0.4816\n",
      "Current minimum: -0.4939\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "dict_param: {'n_estimators': np.int64(75), 'max_depth': np.int64(33), 'min_samples_split': np.int64(2), 'min_samples_leaf': np.int64(7), 'max_features': np.str_('log2'), 'bootstrap': np.True_, 'criterion': np.str_('gini')}\n",
      "metric: 0.4763157894736842\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.4685\n",
      "Function value obtained: -0.4763\n",
      "Current minimum: -0.4939\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "dict_param: {'n_estimators': np.int64(274), 'max_depth': np.int64(48), 'min_samples_split': np.int64(19), 'min_samples_leaf': np.int64(6), 'max_features': np.str_('log2'), 'bootstrap': np.True_, 'criterion': np.str_('gini')}\n",
      "metric: 0.49736842105263157\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.0599\n",
      "Function value obtained: -0.4974\n",
      "Current minimum: -0.4974\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "dict_param: {'n_estimators': np.int64(403), 'max_depth': np.int64(44), 'min_samples_split': np.int64(5), 'min_samples_leaf': np.int64(7), 'max_features': np.str_('log2'), 'bootstrap': np.True_, 'criterion': np.str_('gini')}\n",
      "metric: 0.49122807017543857\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.8834\n",
      "Function value obtained: -0.4912\n",
      "Current minimum: -0.4974\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "dict_param: {'n_estimators': np.int64(453), 'max_depth': np.int64(10), 'min_samples_split': np.int64(18), 'min_samples_leaf': np.int64(10), 'max_features': np.str_('sqrt'), 'bootstrap': np.False_, 'criterion': np.str_('entropy')}\n",
      "metric: 0.4824561403508772\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.6467\n",
      "Function value obtained: -0.4825\n",
      "Current minimum: -0.4974\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "dict_param: {'n_estimators': np.int64(499), 'max_depth': np.int64(30), 'min_samples_split': np.int64(9), 'min_samples_leaf': np.int64(8), 'max_features': np.str_('sqrt'), 'bootstrap': np.True_, 'criterion': np.str_('gini')}\n",
      "metric: 0.4921052631578947\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.6194\n",
      "Function value obtained: -0.4921\n",
      "Current minimum: -0.4974\n"
     ]
    }
   ],
   "source": [
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import gp_minimize\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train = X_train_trans_scaler\n",
    "y_train = y_train\n",
    "\n",
    "X_test = X_test_trans_scaler\n",
    "y_test = y_test\n",
    "\n",
    "def train_and_save_preds(mdl, name_pred_save:str): \n",
    "    # Iremos treinar no X_train0\n",
    "    mdl.fit(X_train, y_train)\n",
    "    \n",
    "    # Vamos prever no X_train1 (X_train1 nesse caso é dado de validação, pois é um dado fora da amostra de treino\n",
    "    p = mdl.predict(X_test)\n",
    "\n",
    "    # Salvando as previsões\n",
    "    #model_name_train1 = os.path.join(MODELS_FILE_DIR, f\"preds_train1\", name_pred_save) \n",
    "\n",
    "    #jb.dump(p, model_name_train1)\n",
    "    \n",
    "    # Calculando a metrica (y_train1 nesse caso é dado de validação, pois é um dado fora da amostra de treino)\n",
    "    metric = accuracy_score(y_true=y_test.values, y_pred=p)\n",
    "    \n",
    "    # Realizando previses para o X_val1\n",
    "    #p = mdl.predict(X_val1)\n",
    "    #model_name_val1 = os.path.join(MODELS_FILE_DIR, f\"preds_val1\", name_pred_save) \n",
    "    #jb.dump(p, model_name_val1)\n",
    "    \n",
    "    #p = mdl.predict(X_test)\n",
    "    #model_name_test = os.path.join(MODELS_FILE_DIR, f\"preds_test/linear_Reg_{C_value}_{multi_class}_{solver}_{penalty}.pkl.z\") \n",
    "    #jb.dump(p, model_name_test)\n",
    "\n",
    "    return metric   \n",
    "\n",
    "\n",
    "def tune_random_forest(params):\n",
    "    \"\"\"\n",
    "    Realiza o tune do modelo\n",
    "\n",
    "    Realiza o treino em dados do nivel_0 e realiza previsões para dados de outros niveis\n",
    "    \"\"\"\n",
    "\n",
    "    n_estimators = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_samples_split = params[2]\n",
    "    min_samples_leaf = params[3]\n",
    "    max_features = params[4]\n",
    "    bootstrap = params[5]\n",
    "    criterion = params[6]\n",
    "\n",
    "    \n",
    "        \n",
    "    mdl = RandomForestClassifier(n_estimators = n_estimators,\n",
    "                                max_depth = max_depth,\n",
    "                                min_samples_split = min_samples_split,\n",
    "                                min_samples_leaf = min_samples_leaf,\n",
    "                                max_features = max_features,\n",
    "                                bootstrap = bootstrap,\n",
    "                                criterion = criterion)\n",
    "\n",
    "\n",
    "    name_pred_save = f\"random_forest_{n_estimators}_{max_depth}_{min_samples_split}_{min_samples_leaf}_{max_features}_{bootstrap}_{criterion}.pkl.z\"\n",
    "    metric = train_and_save_preds(mdl=mdl, \n",
    "                                  name_pred_save=name_pred_save)\n",
    "                                  \n",
    "    dict_param = {\n",
    "        \"n_estimators\":n_estimators,\n",
    "        \"max_depth\":max_depth,\n",
    "        \"min_samples_split\":min_samples_split,\n",
    "        \"min_samples_leaf\":min_samples_leaf,\n",
    "        \"max_features\":max_features,\n",
    "        \"bootstrap\":bootstrap,\n",
    "        \"criterion\":criterion,\n",
    "    }\n",
    "    print(f\"dict_param: {dict_param}\")\n",
    "    print(f\"metric: {metric}\")\n",
    "    \n",
    "    return -metric\n",
    "\n",
    "# Definindo o espaço de busca\n",
    "space = [\n",
    "    Integer(50, 500, name='n_estimators'),  # Número de árvores na floresta\n",
    "    Integer(5, 50, name='max_depth'),       # Profundidade máxima de cada árvore\n",
    "    Integer(2, 20, name='min_samples_split'), # Número mínimo de amostras para dividir um nó\n",
    "    Integer(1, 10, name='min_samples_leaf'),  # Número mínimo de amostras por folha\n",
    "    Categorical(['sqrt', 'log2'], name='max_features'), # Número de características para divisão\n",
    "    Categorical([True, False], name='bootstrap'), # Se usa ou não amostragem com reposição\n",
    "    Categorical(['gini', 'entropy'], name='criterion') # Função de qualidade de divisão\n",
    "]\n",
    "\n",
    "# Chamando o otimizador\n",
    "res = gp_minimize(tune_random_forest, \n",
    "                  space, \n",
    "                  random_state=0, \n",
    "                  verbose=1, \n",
    "                  n_calls=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Treinando GridSearchCV\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Parameter grid is not a dict (Integer(low=50, high=500, prior='uniform', transform='identity'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[196], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#printing best fits and time elapsed\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_trans_scaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(gs\u001b[38;5;241m.\u001b[39mbest_score_, gs\u001b[38;5;241m.\u001b[39mbest_params_,  time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#testing models on unseen data \u001b[39;00m\n",
      "File \u001b[0;32m/media/guilherme/ssd_m2_data/My_projects/Jogos/bet-soccer/venv/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/guilherme/ssd_m2_data/My_projects/Jogos/bet-soccer/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/media/guilherme/ssd_m2_data/My_projects/Jogos/bet-soccer/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     evaluate_candidates(\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/media/guilherme/ssd_m2_data/My_projects/Jogos/bet-soccer/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:122\u001b[0m, in \u001b[0;36mParameterGrid.__init__\u001b[0;34m(self, param_grid)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grid \u001b[38;5;129;01min\u001b[39;00m param_grid:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(grid, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 122\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter grid is not a dict (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m grid\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Parameter grid is not a dict (Integer(low=50, high=500, prior='uniform', transform='identity'))"
     ]
    }
   ],
   "source": [
    "#tuning logistic regression\n",
    "print('>>> Treinando GridSearchCV')\n",
    "#parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "# 'fit_intercept': (True, False), 'solver' : ('newton-cg', 'sag', 'saga', 'lbfgs'), 'class_weight' : (None, 'balanced')}\n",
    "\n",
    "parameters = space\n",
    "\n",
    "clf = list_model[6]['mdl']\n",
    "gs = GridSearchCV(clf, parameters, \n",
    "                  scoring='accuracy', \n",
    "                  cv=3,\n",
    "                  )\n",
    "start = time.time()\n",
    "\n",
    "#printing best fits and time elapsed\n",
    "gs.fit(X_train_trans_scaler, y_train)\n",
    "print(gs.best_score_, gs.best_params_,  time.time() - start)\n",
    "\n",
    "#testing models on unseen data \n",
    "tpred_lr = gs.best_estimator_.predict(X_test_trans_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_precision(pred=tpred_lr, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, fit_intercept=False, max_iter=3000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, fit_intercept=False, max_iter=3000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, fit_intercept=False, max_iter=3000)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melhor etimador do GridSearchCV\n",
    "\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.322     0.170     0.223       329\n",
      "           1      0.426     0.611     0.502       298\n",
      "           2      0.590     0.620     0.605       513\n",
      "\n",
      "    accuracy                          0.488      1140\n",
      "   macro avg      0.446     0.467     0.443      1140\n",
      "weighted avg      0.470     0.488     0.468      1140\n",
      "\n",
      "RandomForestClassifier: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.291     0.495     0.366       329\n",
      "           1      0.217     0.017     0.031       298\n",
      "           2      0.460     0.499     0.479       513\n",
      "\n",
      "    accuracy                          0.372      1140\n",
      "   macro avg      0.323     0.337     0.292      1140\n",
      "weighted avg      0.348     0.372     0.329      1140\n",
      "\n",
      "GradientBoostingClassifier: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.287     0.748     0.415       329\n",
      "           1      0.145     0.054     0.078       298\n",
      "           2      0.393     0.133     0.198       513\n",
      "\n",
      "    accuracy                          0.289      1140\n",
      "   macro avg      0.275     0.311     0.231      1140\n",
      "weighted avg      0.298     0.289     0.229      1140\n",
      "\n",
      "KNeighborsClassifier: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.290     0.690     0.408       329\n",
      "           1      0.296     0.228     0.258       298\n",
      "           2      0.559     0.138     0.222       513\n",
      "\n",
      "    accuracy                          0.321      1140\n",
      "   macro avg      0.382     0.352     0.296      1140\n",
      "weighted avg      0.413     0.321     0.285      1140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV: \\n', classification_report(y_test, tpred_lr, digits = 3))\n",
    "print('RandomForestClassifier: \\n', classification_report(y_test, tpred_rf, digits = 3))\n",
    "print('GradientBoostingClassifier: \\n', classification_report(y_test, tpred_gb, digits = 3))\n",
    "print('KNeighborsClassifier: \\n', classification_report(y_test, tpred_knn, digits = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_X = df_X[featured_columns]\n",
    "\n",
    "#X_valida = ref.transform(df_X)\n",
    "\n",
    "X_valida = scaler.fit_transform(df_X)\n",
    "\n",
    "# testing models on unseen data \n",
    "pred_lr = gs.best_estimator_.predict(X_valida)\n",
    "pred_rf = rf.predict(X_valida)\n",
    "pred_gb = gb.predict(X_valida)\n",
    "pred_knn = knn.predict(X_valida)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_valida_models = pd.DataFrame()\n",
    "\n",
    "df_valida_models['pred_lr'] = pred_lr\n",
    "df_valida_models['pred_rf'] = pred_rf\n",
    "df_valida_models['pred_gb'] = pred_gb\n",
    "df_valida_models['pred_knn'] = pred_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_valida_models.iterrows():\n",
    "    pred_mode = row.mode()\n",
    "        # Verificando se a moda é unimodal (apenas um valor)\n",
    "    if len(pred_mode) == 1:\n",
    "        # Se for unimodal, pegue o valor\n",
    "        result = pred_mode.item()\n",
    "        df_valida_models.loc[idx, 'pred_mode'] = result\n",
    "    else:\n",
    "        # Se for bimodal ou multimodal, trate como necessário (por exemplo, retornando None)\n",
    "        result = row['pred_lr']\n",
    "        df_valida_models.loc[idx, 'pred_mode'] = result\n",
    "\n",
    "df_valida_models['pred_mode'] = df_valida_models['pred_mode'].astype(int)\n",
    "df_valida_models['winner'] = winner.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acertos_mode\n",
       "True     0.522678\n",
       "False    0.477322\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valida_models['acertos_mode'] = df_valida_models['pred_mode'] == df_valida_models['winner']\n",
    "\n",
    "df_valida_models['acertos_mode'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(is_hit_pred_lr\n",
       " False    0.500593\n",
       " True     0.499407\n",
       " Name: proportion, dtype: float64,\n",
       " is_hit_pred_rf\n",
       " True     0.502966\n",
       " False    0.497034\n",
       " Name: proportion, dtype: float64,\n",
       " is_hit_pred_gb\n",
       " False    0.507711\n",
       " True     0.492289\n",
       " Name: proportion, dtype: float64,\n",
       " is_hit_pred_knn\n",
       " False    0.562278\n",
       " True     0.437722\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valida_models['is_hit_pred_lr'] = df_valida_models['pred_lr'] == df_valida_models['winner']\n",
    "df_valida_models['is_hit_pred_rf'] = df_valida_models['pred_rf'] == df_valida_models['winner']\n",
    "df_valida_models['is_hit_pred_gb'] = df_valida_models['pred_gb'] == df_valida_models['winner']\n",
    "df_valida_models['is_hit_pred_knn'] = df_valida_models['pred_knn'] == df_valida_models['winner']\n",
    "\n",
    "\n",
    "is_hit_pred_lr = df_valida_models['is_hit_pred_lr'].value_counts(normalize=True) \n",
    "is_hit_pred_rf = df_valida_models['is_hit_pred_rf'].value_counts(normalize=True) \n",
    "is_hit_pred_gb = df_valida_models['is_hit_pred_gb'].value_counts(normalize=True) \n",
    "is_hit_pred_knn = df_valida_models['is_hit_pred_knn'].value_counts(normalize=True)\n",
    "\n",
    "is_hit_pred_lr, is_hit_pred_rf, is_hit_pred_gb, is_hit_pred_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_lr</th>\n",
       "      <th>pred_rf</th>\n",
       "      <th>pred_gb</th>\n",
       "      <th>pred_knn</th>\n",
       "      <th>pred_mode</th>\n",
       "      <th>winner</th>\n",
       "      <th>acertos_mode</th>\n",
       "      <th>is_hit_pred_lr</th>\n",
       "      <th>is_hit_pred_rf</th>\n",
       "      <th>is_hit_pred_gb</th>\n",
       "      <th>is_hit_pred_knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>843 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_lr  pred_rf  pred_gb  pred_knn  pred_mode  winner  acertos_mode  \\\n",
       "0          2        2        2         0          2       2          True   \n",
       "1          2        2        2         2          2       2          True   \n",
       "2          1        0        1         0          0       0          True   \n",
       "3          2        2        2         2          2       2          True   \n",
       "4          2        2        2         2          2       2          True   \n",
       "..       ...      ...      ...       ...        ...     ...           ...   \n",
       "838        2        2        2         2          2       2          True   \n",
       "839        2        2        2         0          2       2          True   \n",
       "840        2        2        2         0          2       2          True   \n",
       "841        2        2        2         2          2       2          True   \n",
       "842        1        1        2         2          1       1          True   \n",
       "\n",
       "     is_hit_pred_lr  is_hit_pred_rf  is_hit_pred_gb  is_hit_pred_knn  \n",
       "0              True            True            True            False  \n",
       "1              True            True            True             True  \n",
       "2             False            True           False             True  \n",
       "3              True            True            True             True  \n",
       "4              True            True            True             True  \n",
       "..              ...             ...             ...              ...  \n",
       "838            True            True            True             True  \n",
       "839            True            True            True            False  \n",
       "840            True            True            True            False  \n",
       "841            True            True            True             True  \n",
       "842            True            True           False            False  \n",
       "\n",
       "[843 rows x 11 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valida_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_lr</th>\n",
       "      <th>pred_rf</th>\n",
       "      <th>pred_gb</th>\n",
       "      <th>pred_knn</th>\n",
       "      <th>pred_mode</th>\n",
       "      <th>winner</th>\n",
       "      <th>acertos_mode</th>\n",
       "      <th>is_hit_pred_lr</th>\n",
       "      <th>is_hit_pred_rf</th>\n",
       "      <th>is_hit_pred_gb</th>\n",
       "      <th>is_hit_pred_knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_lr  pred_rf  pred_gb  pred_knn  pred_mode  winner  acertos_mode  \\\n",
       "6          1        1        2         2          1       2         False   \n",
       "12         1        1        1         1          1       2         False   \n",
       "15         2        0        2         0          0       2         False   \n",
       "16         2        0        0         0          0       2         False   \n",
       "22         2        0        0         1          0       2         False   \n",
       "..       ...      ...      ...       ...        ...     ...           ...   \n",
       "799        1        0        2         0          0       2         False   \n",
       "806        1        1        1         1          1       2         False   \n",
       "810        2        0        2         0          0       1         False   \n",
       "817        1        2        0         0          0       1         False   \n",
       "837        2        2        2         0          0       1         False   \n",
       "\n",
       "     is_hit_pred_lr  is_hit_pred_rf  is_hit_pred_gb  is_hit_pred_knn  \n",
       "6             False           False            True             True  \n",
       "12            False           False           False            False  \n",
       "15             True           False            True            False  \n",
       "16             True           False           False            False  \n",
       "22             True           False           False            False  \n",
       "..              ...             ...             ...              ...  \n",
       "799           False           False            True            False  \n",
       "806           False           False           False            False  \n",
       "810           False           False           False            False  \n",
       "817            True           False           False            False  \n",
       "837           False           False           False            False  \n",
       "\n",
       "[211 rows x 11 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valida_models[df_valida_models['acertos_mode'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1200 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "40000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pred-soccer-Ppg3ABQz-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
